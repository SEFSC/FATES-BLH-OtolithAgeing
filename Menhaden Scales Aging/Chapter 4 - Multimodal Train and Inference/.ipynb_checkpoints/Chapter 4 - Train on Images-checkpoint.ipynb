{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Train on Multimodal Data\n",
    "\n",
    "Here we will show how to train the model on a folder of images along with associated metadata.\n",
    "\n",
    "## Data Loader\n",
    "Again, the first thing we need to do is define our dataloader (what kind of data we expect).  Different from chapter 2, we expect there to be an additional csv file with our age label information as well.  \n",
    "\n",
    "Typically this data should be split into three different sets, a training set, a validation set, and a testing set.  The training set (\\~ 60%-70%), as the name suggests is used to actually train the model.  The validation set (\\~10%-20%) is used during training to choose the best performing model.  This is necessary since the model changes at each step of the training phase and the model at the very end of training may not be the best due to overfitting.  Finally, the testing set (\\~ 10%-20%) is used to evaluate the actual model performance on unseen data (like accuracy).  For this example, we will use the same set of data for all three purposes.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class FishTestDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_path, transform=None):\n",
    "\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=0)\n",
    "        \n",
    "        # Get the directory dataset images\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        # Get the transform methods\n",
    "        self.transforms = transform\n",
    "\n",
    "\n",
    "        # Image Name\n",
    "        self.image_name = np.asarray(self.data_info.iloc[:, 0])\n",
    "        \n",
    "        # Otolith length\n",
    "        self.length = np.asarray(self.data_info.iloc[:, 1])\n",
    "\n",
    "        # Otolith weight\n",
    "        self.wt = np.asarray(self.data_info.iloc[:, 2])\n",
    "\n",
    "        # Month\n",
    "        self.month = np.asarray(self.data_info.iloc[:, 3])\n",
    "        \n",
    "        # Fish Age\n",
    "        self.age = np.asarray(self.data_info.iloc[:, 4])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, str(self.image_name[index]))\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        wt_l_m = torch.tensor([(self.wt[index] - 163)/(82), (self.length[index] - 211)/ (35.5), (self.month[index]-7.4)/(1.9)])\n",
    "\n",
    "        \n",
    "        if(self.age[index] < 5):\n",
    "          label_age = self.age[index]\n",
    "        else:\n",
    "          label_age = 4\n",
    "            \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return (image,wt_l_m) , self.image_name[index], label_age\n",
    "        \n",
    "data_dir = 'cropped'\n",
    "csv_path = \"train.csv\"\n",
    "data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "train_dataset = FishTestDataset( data_dir, csv_path, data_transforms)\n",
    "test_dataset = FishTestDataset( data_dir, csv_path, data_transforms)\n",
    "val_dataset = FishTestDataset( data_dir, csv_path, data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(test_dataset, batch_size=24, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(val_dataset, batch_size=24, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Model Architecture for Multi-Modal Data\n",
    "\n",
    "We copy the basic resnet model building block code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function creating a 3x3 convolutional layer\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"\n",
    "    Function to create a 3x3 convolutional layer with padding.\n",
    "\n",
    "    Args:\n",
    "    - in_planes (int): Number of input channels.\n",
    "    - out_planes (int): Number of output channels.\n",
    "    - stride (int): Stride value for the convolution (default: 1).\n",
    "    - groups (int): Number of groups for grouped convolution (default: 1).\n",
    "    - dilation (int): Dilation rate for the convolution (default: 1).\n",
    "\n",
    "    Returns:\n",
    "    - conv_layer (nn.Conv2d): The created 3x3 convolutional layer.\n",
    "    \"\"\"\n",
    "    # Create a 3x3 convolutional layer with the specified parameters\n",
    "    conv_layer = nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "    return conv_layer\n",
    "\n",
    "# function creating a 1x1 convolutional layer\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"\n",
    "    Function to create a 1x1 convolutional layer.\n",
    "\n",
    "    Args:\n",
    "    - in_planes (int): Number of input channels.\n",
    "    - out_planes (int): Number of output channels.\n",
    "    - stride (int): Stride value for the convolution (default: 1).\n",
    "\n",
    "    Returns:\n",
    "    - conv_layer (nn.Conv2d): The created 1x1 convolutional layer.\n",
    "    \"\"\"\n",
    "    # Create a 1x1 convolutional layer with the specified parameters\n",
    "    conv_layer = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    return conv_layer\n",
    "\n",
    "# module to define a BasicBlock residual block for the resnet model\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Basic residual block implementation used in ResNet.\n",
    "\n",
    "        Args:\n",
    "        - inplanes (int): Number of input channels.\n",
    "        - planes (int): Number of output channels.\n",
    "        - stride (int): Stride value for the convolutional layers (default: 1).\n",
    "        - downsample (nn.Module, optional): Downsample module (default: None).\n",
    "        - groups (int): Number of groups for grouped convolution (default: 1).\n",
    "        - base_width (int): Base width for grouped convolution (default: 64).\n",
    "        - dilation (int): Dilation rate for dilated convolution (default: 1).\n",
    "        - norm_layer (Callable[..., nn.Module], optional): Normalization layer (default: nn.BatchNorm2d).\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)  # 3x3 convolutional layer\n",
    "        self.bn1 = norm_layer(planes)  # Batch normalization\n",
    "        self.relu = nn.ReLU(inplace=True)  # ReLU activation function\n",
    "        self.conv2 = conv3x3(planes, planes)  # 3x3 convolutional layer\n",
    "        self.bn2 = norm_layer(planes)  # Batch normalization\n",
    "        self.downsample = downsample  # Downsample module\n",
    "        self.stride = stride  # Stride value for the convolutional layers\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the BasicBlock.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - out (Tensor): Output tensor.\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)  # First convolutional layer\n",
    "        out = self.bn1(out)  # Batch normalization\n",
    "        out = self.relu(out)  # ReLU activation\n",
    "\n",
    "        out = self.conv2(out)  # Second convolutional layer\n",
    "        out = self.bn2(out)  # Batch normalization\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)  # Downsample the input if needed\n",
    "\n",
    "        out += identity  # Add the residual connection\n",
    "        out = self.relu(out)  # ReLU activation\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# module to define a Bottleneck residual block for the resnet model\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution (self.conv2)\n",
    "    # while the original implementation places the stride at the first 1x1 convolution (self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\" (https://arxiv.org/abs/1512.03385).\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Bottleneck residual block implementation used in ResNet.\n",
    "\n",
    "        Args:\n",
    "        - inplanes (int): Number of input channels.\n",
    "        - planes (int): Number of output channels.\n",
    "        - stride (int): Stride value for the convolutional layers (default: 1).\n",
    "        - downsample (nn.Module, optional): Downsample module (default: None).\n",
    "        - groups (int): Number of groups for grouped convolution (default: 1).\n",
    "        - base_width (int): Base width for grouped convolution (default: 64).\n",
    "        - dilation (int): Dilation rate for dilated convolution (default: 1).\n",
    "        - norm_layer (Callable[..., nn.Module], optional): Normalization layer (default: nn.BatchNorm2d).\n",
    "        \"\"\"\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)  # 1x1 convolutional layer\n",
    "        self.bn1 = norm_layer(width)  # Batch normalization\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)  # 3x3 convolutional layer\n",
    "        self.bn2 = norm_layer(width)  # Batch normalization\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)  # 1x1 convolutional layer\n",
    "        self.bn3 = norm_layer(planes * self.expansion)  # Batch normalization\n",
    "        self.relu = nn.ReLU(inplace=True)  # ReLU activation function\n",
    "        self.downsample = downsample  # Downsample module\n",
    "        self.stride = stride  # Stride value for the convolutional layers\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Bottleneck.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - out (Tensor): Output tensor.\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)  # First 1x1 convolutional layer\n",
    "        out = self.bn1(out)  # Batch normalization\n",
    "        out = self.relu(out)  # ReLU activation\n",
    "\n",
    "        out = self.conv2(out)  # 3x3 convolutional layer\n",
    "        out = self.bn2(out)  # Batch normalization\n",
    "        out = self.relu(out)  # ReLU activation\n",
    "\n",
    "        out = self.conv3(out)  # Second 1x1 convolutional layer\n",
    "        out = self.bn3(out)  # Batch normalization\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)  # Downsample the input\n",
    "\n",
    "        out += identity  # Residual connection\n",
    "        out = self.relu(out)  # ReLU activation\n",
    "\n",
    "        return out\n",
    "\n",
    "# module defining modified RESNET backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we modify the specific model architecture to include a metadata input branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            block: Type[Union[BasicBlock, Bottleneck]],\n",
    "            layers: List[int],\n",
    "            num_classes: int = 5,\n",
    "            img_size: int = 64,\n",
    "            metadata_size: int = 32,\n",
    "            zero_init_residual: bool = False,\n",
    "            groups: int = 1,\n",
    "            width_per_group: int = 64,\n",
    "            replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # If norm_layer is not provided, default to nn.BatchNorm2d\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.img_size = img_size\n",
    "        self.metadata_size = metadata_size\n",
    "\n",
    "        # Check if replace_stride_with_dilation is provided\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # If not provided, set it to a default value of [False, False, False]\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Residual layers (layer1, layer2, layer3, layer4)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "\n",
    "        # Adaptive average pooling and fully connected layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_meta = nn.Linear(3, metadata_size)\n",
    "        self.fc_img = nn.Linear(512 * block.expansion, img_size)\n",
    "\n",
    "        self.fc_combined = nn.Linear(metadata_size +img_size,num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck) and m.bn3.weight is not None:\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "\n",
    "        # Adjust dilation and stride if dilate is True\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "\n",
    "        # Create downsample layer if stride != 1 or number of input channels is different from output channels\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # Add the first block of the layer with potential downsampling\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        # Add the rest of the blocks in the layer\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor, metadata: Tensor, spectral_data: Tensor) -> Tensor:\n",
    "\n",
    "        metadata = F.relu(self.fc_meta(metadata))\n",
    "        \n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)  # First residual layer\n",
    "        x = self.layer2(x)  # Second residual layer\n",
    "        x = self.layer3(x)  # Third residual layer\n",
    "        x = self.layer4(x)  # Fourth residual layer\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_img(x)\n",
    "\n",
    "        total_length =  self.img_size + self.metadata_size\n",
    "\n",
    "        combined_features = torch.cat((x, metadata), dim=1)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        x = self.fc_combined(combined_features)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor, metadata: Tensor, spectral_data: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet model.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input image tensor.\n",
    "            metadata (Tensor): Metadata tensor.\n",
    "            spectral_data (Tensor): Spectral data tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        return self._forward_impl(x, metadata, spectral_data)\n",
    "\n",
    "\n",
    "# function to train the revised Resnet model\n",
    "def resnet_new(block: Type[Union[BasicBlock, Bottleneck]],\n",
    "               layers: List[int],\n",
    "               pretrained: bool = False,\n",
    "               num_classes: int = 5,\n",
    "               metadata_size: int = 32,\n",
    "               img_size: int = 64,\n",
    "               progress: bool = True,\n",
    "               **kwargs: Any) -> ResNet:\n",
    "    \"\"\"\n",
    "    Create a new ResNet model.\n",
    "\n",
    "    Args:\n",
    "        block (Type[Union[BasicBlock, Bottleneck]]): Type of the residual block (BasicBlock or Bottleneck).\n",
    "        layers (List[int]): List specifying the number of blocks in each layer of the network.\n",
    "        pretrained (bool): Whether to load a pretrained ResNet model. Default is False.\n",
    "        num_classes (int): Number of output classes. Default is 17.\n",
    "        metadata_size (int): Size of the metadata input. Default is 32.\n",
    "        img_size (int): Size of the image input. Default is 64.\n",
    "        spectral_size (int): Size of the spectral data input. Default is 32.\n",
    "        progress (bool): Whether to display a progress bar when downloading pretrained weights. Default is True.\n",
    "        **kwargs (Any): Additional keyword arguments to pass to the ResNet constructor.\n",
    "\n",
    "    Returns:\n",
    "        ResNet: ResNet model.\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        # Load a pretrained ResNet18 model\n",
    "        model = resnet.resnet18(pretrained=True, progress=progress)\n",
    "        # Update the final fully connected layer for the desired number of classes\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        return model\n",
    "\n",
    "    # Update the kwargs dictionary with the specified parameters\n",
    "    kwargs['metadata_size'] = metadata_size\n",
    "    kwargs['img_size'] = img_size\n",
    "    kwargs['mode'] = mode\n",
    "    kwargs['block'] = block\n",
    "    kwargs['layers'] = layers\n",
    "\n",
    "    # Create a new ResNet model with modified parameters\n",
    "    model = ResNet(**kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load Pretrained Model\n",
    "Before we can train the model, we first have to define the model architecture and load some pretrained weight.  We use pytorch resnet18 model and it's corresponding imagenet pretrained weights.  Using pretrained weights reduces training speed and can also improve final model performance if using limited training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights, get_weight\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(num_classes = 5)\n",
    "loaded_state_dict = torch.hub.load_state_dict_from_url(\"https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth\")\n",
    "current_model_dict = model.state_dict()\n",
    "new_state_dict={k:v if v.size()==current_model_dict[k].size()  else  current_model_dict[k] for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "model.load_state_dict(new_state_dict, strict = False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Hyperparameters\n",
    "Before we start training, there are a few training parameters we need to define.  First is the number of training epochs, which is how many times we use the entire training set.  One epoch of training passes once we've gone through the training set once.  In each epoch, a training step is called an iteration, where N images are loaded at a time based on batch size.  \n",
    "Another important hyperparameter is learning rate and learning rate schedule.  The learning rate determines how fast the model gets training.  Having a too large or too small learning rate can drastically affect final model performance.  Typically, as training progresses, learning rate is decreased through a learning rate scheduler.  In this case, at predefined epoch points, the learning rate is multiplied by gamma (<1).\n",
    "Finally, we have to define what loss function we use for training.  For simple classification, we choose cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "num_epochs = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 15, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now we train the model and also evaluate on the validation set at each epoch.  If validation accuracy at current epoch is better than previous epochs, the current model weights are saved as best_model.pth.  Finally, at the end of training, the final model weights are also saved as final_model.pth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n",
      "saving best model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "train Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 100.0, 0.0, 0.0, 0.0]\n",
      "validation Loss: 0.0000 Average Accuracy: 100.0000\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_res = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for images, imagename, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            output = model(images)#inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # statistics\n",
    "        _, preds = torch.max(output, 1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100.0 * running_corrects / len(train_loader.dataset)\n",
    "    running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "    print(running_res)\n",
    "    print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(\"train\", epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_res = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    for images, imagename, labels in tqdm(val_loader):\n",
    "    \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            output = model(images)#inputs)\n",
    "            \n",
    "        # statistics\n",
    "        _, preds = torch.max(output, 1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = 100.0 * running_corrects / len(val_loader.dataset)\n",
    "    running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "    print(running_res)\n",
    "    print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(\"validation\", epoch_loss, epoch_acc))\n",
    "    if(epoch_acc > best_acc):\n",
    "        print(\"saving best model\")\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        res = running_res.copy()\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "torch.save(model.state_dict(), 'final_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

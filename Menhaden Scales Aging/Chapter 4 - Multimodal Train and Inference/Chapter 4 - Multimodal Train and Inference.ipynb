{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2016ee2",
    "outputId": "9687b6eb-5b00-48b8-b113-c07edc6ce59e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\anaconda3\\envs\\aging\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#@title imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "JltlZFIBjbZo",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_one_hot(label, num_classes):\n",
    "    batch_size = label.shape[0]\n",
    "    onehot_label = torch.zeros((batch_size, num_classes))\n",
    "    onehot_label = onehot_label.scatter_(1, label.unsqueeze(1).detach().cpu(), 1)\n",
    "    onehot_label = (onehot_label.type(torch.FloatTensor)).to(label.device)\n",
    "    return onehot_label\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )\n",
    "\n",
    "class FocalLoss2(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        label = get_one_hot(target_tensor, self.num_classes)\n",
    "        #p = self.sigmoid(input_tensor)\n",
    "        p = torch.clamp(self.sigmoid(input_tensor), min=eps, max=1-eps)\n",
    "        focal_weights = torch.pow((1-p)*label + p * (1-label), self.gamma)\n",
    "        loss = F.binary_cross_entropy_with_logits(input_tensor, label, reduction = 'none') * focal_weights\n",
    "        loss = (loss ).sum() / input_tensor.shape[0]\n",
    "        return loss\n",
    "\n",
    "class CBFocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., beta = 0.999, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "        self.classlist = [1.0, 176.0, 911.0, 215.0, 41.0]#[75, 1414, 905, 242, 84]\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.class_balanced_weight = np.array([(1-self.beta)/(1- self.beta ** N) for N in self.classlist])\n",
    "        self.class_balanced_weight = torch.FloatTensor(self.class_balanced_weight / np.sum(self.class_balanced_weight) * self.num_classes*10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        weight = (self.class_balanced_weight[target_tensor]).to(\"cuda\")\n",
    "        label = get_one_hot(target_tensor, self.num_classes)\n",
    "        p = torch.clamp(self.sigmoid(input_tensor), min=eps, max=1-eps)\n",
    "        focal_weights = torch.pow((1-p)*label + p * (1-label), self.gamma)\n",
    "        loss = F.binary_cross_entropy_with_logits(input_tensor, label, reduction = 'none') * focal_weights\n",
    "        loss = (loss * weight.view(-1, 1)).sum() / input_tensor.shape[0]\n",
    "        return loss\n",
    "\n",
    "class CBCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 beta = 0.999, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "        self.classlist = [75, 1414, 905, 242, 84]\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.class_balanced_weight = np.array([(1-self.beta)/(1- self.beta ** N) for N in self.classlist])\n",
    "        self.class_balanced_weight = torch.FloatTensor(self.class_balanced_weight / np.sum(self.class_balanced_weight) * self.num_classes).to(\"cuda\")\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        weights = (self.class_balanced_weight).to(\"cuda\")\n",
    "\n",
    "        loss = F.cross_entropy(input_tensor, target_tensor, weight=weights)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "id": "826c523f"
   },
   "outputs": [],
   "source": [
    "#@title dataset\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self, csv_path, dataset_dir, transform=None):\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=0)\n",
    "\n",
    "        # Get the directory dataset images\n",
    "        self.dataset_dir = dataset_dir\n",
    "\n",
    "        # Get the transform methods\n",
    "        self.transforms = transform\n",
    "\n",
    "\n",
    "        # Image Name\n",
    "        self.image_name = np.asarray(self.data_info.iloc[:, 2])\n",
    "\n",
    "\n",
    "        # Otolith length\n",
    "        self.length = np.asarray(self.data_info.iloc[:, 6])\n",
    "\n",
    "        # Otolith weight\n",
    "        self.wt = np.asarray(self.data_info.iloc[:, 7])\n",
    "\n",
    "        # Month\n",
    "        self.month = np.asarray(self.data_info.iloc[:, 4])\n",
    "\n",
    "        # Fish Age\n",
    "        self.age = np.asarray(self.data_info.iloc[:, 8])\n",
    "\n",
    "        print(len(self.age), len(self.image_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #img_path = os.path.join(self.dataset_dir, str(self.image_name[index]) + '.jpg')\n",
    "        #image = Image.open(img_path)\n",
    "        wt_l_m = torch.tensor([(self.wt[index] - 163)/(82), (self.length[index] - 211)/ (35.5), (self.month[index]-7.4)/(1.9)])\n",
    "        if(self.age[index] < 5):\n",
    "          label_age = self.age[index]\n",
    "        else:\n",
    "          label_age = 4\n",
    "        #label = torch.from_numpy(np.array(label_age))\n",
    "\n",
    "        #if self.transforms:\n",
    "        #    image = self.transforms(image)\n",
    "\n",
    "        return (wt_l_m,wt_l_m) , label_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53ede8f0",
    "outputId": "72f301da-6bde-4c1e-c593-01422810530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3330 3330\n",
      "3330 3330\n",
      "3330 3330\n",
      "967 967\n",
      "499 499\n"
     ]
    }
   ],
   "source": [
    "#@title load data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = 'F:/Scales/Atlantic Menhaden'\n",
    "train_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Train_Data.csv')\n",
    "test_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Test_Data.csv')\n",
    "val_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Val_Data.csv')\n",
    "gulf_train_csv_path = os.path.join(data_dir,\"Gulf Menhaden/gulf_train.csv\")\n",
    "gulf_test_csv_path = os.path.join(data_dir,\"Gulf Menhaden/gulf_test.csv\")\n",
    "img_dir = os.path.join(data_dir, 'Cropped Images')\n",
    "img_dir_gulf = os.path.join(data_dir, 'Gulf Menhaden/Gulf Cropped')\n",
    "\n",
    "\n",
    "data_transforms_train = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(299),\n",
    "            transforms.RandomCrop(299),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees = 20),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(299),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_dataset = FishDataset(train_csv_path, img_dir, data_transforms_train)\n",
    "class_weight = np.array([1.0/75.0, 1.0/1414, 1.0/905, 1.0/242, 1.0/84])*1414\n",
    "samples_weight = np.array([class_weight[min(t,4)] for t in train_dataset.age])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "#print(samples_weight)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(FishDataset(train_csv_path, img_dir, data_transforms_train)))\n",
    "\n",
    "\n",
    "#train_loader = DataLoader(FishDataset(gulf_train_csv_path, img_dir_gulf, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "#train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "#test_loader = DataLoader(FishDataset(gulf_test_csv_path, img_dir_gulf, data_transforms), batch_size=32, shuffle=True, drop_last=True)\n",
    "#val_loader = DataLoader(FishDataset(gulf_train_csv_path, img_dir_gulf, data_transforms), batch_size=3, shuffle=True, drop_last=True)\n",
    "\n",
    "train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=24, shuffle=True, drop_last=False)\n",
    "#train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(FishDataset(test_csv_path, img_dir, data_transforms), batch_size=24, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(FishDataset(val_csv_path, img_dir, data_transforms), batch_size=24, shuffle=True, drop_last=False)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in [\"train\", \"val\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "92528e95",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Inception Network\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, Any, Optional, Tuple, List\n",
    "\n",
    "__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    # Inception v3 ported from TensorFlow\n",
    "    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth',\n",
    "}\n",
    "\n",
    "InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])\n",
    "InceptionOutputs.__annotations__ = {'logits': Tensor, 'aux_logits': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _InceptionOutputs set here for backwards compat\n",
    "_InceptionOutputs = InceptionOutputs\n",
    "\n",
    "def inception_v3_new(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"Inception3\":\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "    The required minimum input size of the model is 75x75.\n",
    "\n",
    "    .. note::\n",
    "        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n",
    "            Default: *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' in kwargs:\n",
    "            original_aux_logits = kwargs['aux_logits']\n",
    "            kwargs['aux_logits'] = True\n",
    "        else:\n",
    "            original_aux_logits = True\n",
    "        kwargs['init_weights'] = False  # we are loading weights from a pretrained model\n",
    "        model = Inception3(**kwargs)\n",
    "        state_dict = load_state_dict_from_url(model_urls['inception_v3_google'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.AuxLogits = None\n",
    "        return model\n",
    "\n",
    "    return Inception3(**kwargs)\n",
    "\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        inception_blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
    "        init_weights: Optional[bool] = None\n",
    "    ) -> None:\n",
    "        super(Inception3, self).__init__()\n",
    "        if inception_blocks is None:\n",
    "            inception_blocks = [\n",
    "                BasicConv2d, InceptionA, InceptionB, InceptionC,\n",
    "                InceptionD, InceptionE, InceptionAux\n",
    "            ]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(inception_blocks) == 7\n",
    "        conv_block = inception_blocks[0]\n",
    "        inception_a = inception_blocks[1]\n",
    "        inception_b = inception_blocks[2]\n",
    "        inception_c = inception_blocks[3]\n",
    "        inception_d = inception_blocks[4]\n",
    "        inception_e = inception_blocks[5]\n",
    "        inception_aux = inception_blocks[6]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)\n",
    "        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)\n",
    "        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Mixed_5b = inception_a(192, pool_features=32)\n",
    "        self.Mixed_5c = inception_a(256, pool_features=64)\n",
    "        self.Mixed_5d = inception_a(288, pool_features=64)\n",
    "        self.Mixed_6a = inception_b(288)\n",
    "        self.Mixed_6b = inception_c(768, channels_7x7=128)\n",
    "        self.Mixed_6c = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6d = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6e = inception_c(768, channels_7x7=192)\n",
    "        self.AuxLogits: Optional[nn.Module] = None\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = inception_aux(768, num_classes)\n",
    "        self.Mixed_7a = inception_d(768)\n",
    "        self.Mixed_7b = inception_e(1280)\n",
    "        self.Mixed_7c = inception_e(2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc_2_1 = nn.Linear(3, 64)\n",
    "        self.fc3 = nn.Linear(2048, 64)\n",
    "        self.fc2 = nn.Linear(64+64, num_classes)\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    stddev = float(m.stddev) if hasattr(m, 'stddev') else 0.1  # type: ignore\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def get_feature_map(self, x: Tensor, layer):\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        if(layer == 0):\n",
    "          return x\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        if(layer == 1):\n",
    "          return x\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x, x2)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux\n",
    "\n",
    "    def get_fea(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x, x2)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        fea = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(fea)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, fea\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux: Optional[Tensor]) -> InceptionOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return x  # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> InceptionOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux = self._forward(x, x2)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted Inception3 always returns Inception3 Tuple\")\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux)\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        pool_features: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionA, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionB, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels_7x7: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionC, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = conv_block(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionD, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = conv_block(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionE, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = conv_block(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01  # type: ignore[assignment]\n",
    "        self.fc2 = nn.Linear(768 + 3, num_classes)\n",
    "        self.fc2.stddev = 0.001  # type: ignore[assignment]\n",
    "        self.fc_2_1 = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> Tensor:\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        # N x 768 x 17 x 17\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # N x 768 x 5 x 5\n",
    "        x = self.conv0(x)\n",
    "        # N x 128 x 5 x 5\n",
    "        x = self.conv1(x)\n",
    "        # N x 768 x 1 x 1\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 768 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "        # N x 768\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Inception Merge\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, Any, Optional, Tuple, List\n",
    "\n",
    "__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    # Inception v3 ported from TensorFlow\n",
    "    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth',\n",
    "}\n",
    "\n",
    "InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])\n",
    "InceptionOutputs.__annotations__ = {'logits': Tensor, 'aux_logits': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _InceptionOutputs set here for backwards compat\n",
    "_InceptionOutputs = InceptionOutputs\n",
    "\n",
    "def inception_v3_merge(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"Inception3\":\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "    The required minimum input size of the model is 75x75.\n",
    "\n",
    "    .. note::\n",
    "        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n",
    "            Default: *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' in kwargs:\n",
    "            original_aux_logits = kwargs['aux_logits']\n",
    "            kwargs['aux_logits'] = True\n",
    "        else:\n",
    "            original_aux_logits = True\n",
    "        kwargs['init_weights'] = False  # we are loading weights from a pretrained model\n",
    "        model = Inception3(**kwargs)\n",
    "        state_dict = load_state_dict_from_url(model_urls['inception_v3_google'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.AuxLogits = None\n",
    "        return model\n",
    "\n",
    "    return Inception3(**kwargs)\n",
    "\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        inception_blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
    "        init_weights: Optional[bool] = None\n",
    "    ) -> None:\n",
    "        super(Inception3, self).__init__()\n",
    "        if inception_blocks is None:\n",
    "            inception_blocks = [\n",
    "                BasicConv2d, InceptionA, InceptionB, InceptionC,\n",
    "                InceptionD, InceptionE, InceptionAux\n",
    "            ]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(inception_blocks) == 7\n",
    "        conv_block = inception_blocks[0]\n",
    "        inception_a = inception_blocks[1]\n",
    "        inception_b = inception_blocks[2]\n",
    "        inception_c = inception_blocks[3]\n",
    "        inception_d = inception_blocks[4]\n",
    "        inception_e = inception_blocks[5]\n",
    "        inception_aux = inception_blocks[6]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)\n",
    "        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)\n",
    "        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Mixed_5b = inception_a(192, pool_features=32)\n",
    "        self.Mixed_5c = inception_a(256, pool_features=64)\n",
    "        self.Mixed_5d = inception_a(288, pool_features=64)\n",
    "        self.Mixed_6a = inception_b(288)\n",
    "        self.Mixed_6b = inception_c(768, channels_7x7=128)\n",
    "        self.Mixed_6c = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6d = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6e = inception_c(768, channels_7x7=192)\n",
    "        self.AuxLogits: Optional[nn.Module] = None\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = inception_aux(768, num_classes)\n",
    "        self.Mixed_7a = inception_d(768)\n",
    "        self.Mixed_7b = inception_e(1280)\n",
    "        self.Mixed_7c = inception_e(2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc_2_1 = nn.Linear(3, 64)\n",
    "        self.fc3 = nn.Linear(2048, 64)\n",
    "        self.fc2 = nn.Linear(64+64, num_classes)\n",
    "    \n",
    "        self.cond0 = nn.Linear(3,64)\n",
    "        self.cond1 = nn.Linear(64, 64)\n",
    "\n",
    "        self.condproj0 = nn.Linear(64, 32)\n",
    "  \n",
    "        self.condproj1 = nn.Linear(64, 192)\n",
    "        self.condproj2 = nn.Linear(64, 768)\n",
    "\n",
    "        self.gnorm0 = nn.GroupNorm(32, 32)\n",
    "        self.gnorm1 = nn.GroupNorm(192, 192)\n",
    "        self.gnorm2 = nn.GroupNorm(768, 768)\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    stddev = float(m.stddev) if hasattr(m, 'stddev') else 0.1  # type: ignore\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def get_feature_map(self, x: Tensor, layer):\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        if(layer == 0):\n",
    "          return x\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        if(layer == 1):\n",
    "          return x\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        temb = F.relu(self.cond0(x2))\n",
    "        temb = F.relu(self.cond1(temb))\n",
    "\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        \n",
    "        # N x 32 x 149 x 149\n",
    "        #temb0 = F.relu(self.condproj0(temb))\n",
    "        #x = x+ temb0[:,:,None,None]\n",
    "        #x = self.gnorm0(x)\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # N x 192 x 35 x 35\n",
    "        temb1 = F.relu(self.condproj1(temb))\n",
    "        x += temb1[:,:,None,None]\n",
    "        x = self.gnorm1(x)\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        \n",
    "        # N x 768 x 17 x 17\n",
    "        temb2 = F.relu(self.condproj2(temb))\n",
    "        x += temb2[:,:,None,None]\n",
    "        x = self.gnorm2(x)\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "        \n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux\n",
    "\n",
    "    def get_fea(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        fea = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(fea)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, fea\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux: Optional[Tensor]) -> InceptionOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return x  # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> InceptionOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux = self._forward(x, x2)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted Inception3 always returns Inception3 Tuple\")\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux)\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        pool_features: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionA, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionB, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels_7x7: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionC, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = conv_block(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionD, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = conv_block(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionE, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = conv_block(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01  # type: ignore[assignment]\n",
    "        self.fc2 = nn.Linear(768, num_classes)\n",
    "        self.fc2.stddev = 0.001  # type: ignore[assignment]\n",
    "        self.fc_2_1 = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # N x 768 x 17 x 17\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # N x 768 x 5 x 5\n",
    "        x = self.conv0(x)\n",
    "        # N x 128 x 5 x 5\n",
    "        x = self.conv1(x)\n",
    "        # N x 768 x 1 x 1\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 768 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 768\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "id": "jwOb-HogqZnT",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title ViT network backbone\n",
    "import math\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch._six import container_abcs\n",
    "import collections.abc as container_abcs\n",
    "\n",
    "# From PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, container_abcs.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "\n",
    "\n",
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url,\n",
    "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
    "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
    "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
    "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "\n",
    "default_cfgs = {\n",
    "    # patch models\n",
    "    'vit_small_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth',\n",
    "    ),\n",
    "    'vit_base_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth',\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
    "    ),\n",
    "    'vit_base_patch16_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_384-83fb41ba.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_base_patch32_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p32_384-830016f5.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_large_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_224-4ee7a4dc.pth',\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    'vit_large_patch16_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_384-b3be5167.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_large_patch32_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p32_384-9b920ba8.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_huge_patch16_224': _cfg(),\n",
    "    'vit_huge_patch32_384': _cfg(input_size=(3, 384, 384)),\n",
    "    # hybrid models\n",
    "    'vit_small_resnet26d_224': _cfg(),\n",
    "    'vit_small_resnet50d_s3_224': _cfg(),\n",
    "    'vit_base_resnet26d_224': _cfg(),\n",
    "    'vit_base_resnet50d_224': _cfg(),\n",
    "}\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.attn = None\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        self.attn = attn\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class HybridEmbed(nn.Module):\n",
    "    \"\"\" CNN Feature Map Embedding\n",
    "    Extract feature map from CNN, flatten, project to embedding dim.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, img_size=224, feature_size=None, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        assert isinstance(backbone, nn.Module)\n",
    "        img_size = to_2tuple(img_size)\n",
    "        self.img_size = img_size\n",
    "        self.backbone = backbone\n",
    "        if feature_size is None:\n",
    "            with torch.no_grad():\n",
    "                # FIXME this is hacky, but most reliable way of determining the exact dim of the output feature\n",
    "                # map for all networks, the feature metadata has reliable channel and stride info, but using\n",
    "                # stride to calc feature dim requires info about padding of each stage that isn't captured.\n",
    "                training = backbone.training\n",
    "                if training:\n",
    "                    backbone.eval()\n",
    "                o = self.backbone(torch.zeros(1, in_chans, img_size[0], img_size[1]))[-1]\n",
    "                feature_size = o.shape[-2:]\n",
    "                feature_dim = o.shape[1]\n",
    "                backbone.train(training)\n",
    "        else:\n",
    "            feature_size = to_2tuple(feature_size)\n",
    "            feature_dim = self.backbone.feature_info.channels()[-1]\n",
    "        self.num_patches = feature_size[0] * feature_size[1]\n",
    "        self.proj = nn.Linear(feature_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)[-1]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed(\n",
    "                img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        # self.pos_embed_2 = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        # print('pos_embed_2')\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print(drop_path_rate, 'drop_path_rate')\n",
    "        print(drop_rate, 'drop_rate')\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # NOTE as per official impl, we could have a pre-logits representation dense layer + tanh here\n",
    "\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        # x = x + self.pos_embed + self.pos_embed_2\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None):\n",
    "        x = self.forward_features(x)\n",
    "        #x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for i in param_dict:\n",
    "            # if 'head' in i:\n",
    "            #     continue\n",
    "            if 'head' in i or 'attn.qkv.bias' in i:\n",
    "                print('{} parameter is ignore'.format(i))\n",
    "                continue\n",
    "            try:\n",
    "                self.state_dict()[i].copy_(param_dict[i])\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in i :{}: param_dict{} vs self.state_dict(){}'.format(i, param_dict[i].shape, self.state_dict()[i].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "import random\n",
    "\n",
    "class VisionTransformer_mask(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm, thresh=0.0, prob=0.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed(\n",
    "                img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.thresh = thresh\n",
    "        print(thresh, 'thresh')\n",
    "        self.prob = prob\n",
    "        print(prob, 'prob')\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print(drop_path_rate, 'drop_path_rate')\n",
    "        print(drop_rate, 'drop_rate')\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        self.mask_embedding = nn.Parameter(torch.zeros(64, num_patches, embed_dim)) # 768\n",
    "\n",
    "        trunc_normal_(self.mask_embedding, std=.02)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        if self.training:\n",
    "            prob = random.random()\n",
    "            if prob < self.prob:\n",
    "                mask = torch.rand(1, 128, 1).cuda()\n",
    "                mask = torch.where(mask > self.thresh, torch.Tensor([1]).cuda(), torch.Tensor([0]).cuda())  # [64, 16, 8]\n",
    "                x = mask * x + (1 - mask) * self.mask_embedding\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None):\n",
    "        x = self.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for i in param_dict:\n",
    "            if 'head' in i:\n",
    "                continue\n",
    "            try:\n",
    "                self.state_dict()[i].copy_(param_dict[i])\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in i :{}: param_dict{} vs self.state_dict(){}'.format(i, param_dict[i].shape, self.state_dict()[i].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "\n",
    "class PatchEmbed_stride(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, stride_size=20, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        stride_size_tuple = to_2tuple(stride_size)\n",
    "        self.num_x = (img_size[1] - patch_size[1]) // stride_size_tuple[1] + 1\n",
    "        self.num_y = (img_size[0] - patch_size[0]) // stride_size_tuple[0] + 1\n",
    "        print('using stride: {}, and part number is num_y{} * num_x{}'.format(stride_size, self.num_y, self.num_x))\n",
    "        num_patches = self.num_x * self.num_y\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride_size)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "\n",
    "        x = x.flatten(2).transpose(1, 2) # [64, 8, 768]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class TransReID(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, stride_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm,local_feature=False, aie_xishu =1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        self.local_feature = local_feature\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed_stride(\n",
    "                img_size=img_size, patch_size=patch_size, stride_size=stride_size, in_chans=in_chans,\n",
    "                embed_dim=embed_dim)\n",
    "\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "\n",
    "        print('using drop_path_rate is : {}'.format(drop_path_rate))\n",
    "        print('using aie_xishu is : {}'.format(aie_xishu))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print('embed_diim {} mlp_ratio {}'.format(embed_dim, mlp_ratio))\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "        self.AIE_MULTI = aie_xishu\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        trunc_normal_(self.cls_token, std=.02) # 0.01 better\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02) # 0.01 bette # 0.01 betterr\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x, camera_id, view_id):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        if self.local_feature:\n",
    "            for blk in self.blocks[:-1]:\n",
    "                x = blk(x)\n",
    "            return x\n",
    "        else:\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x)\n",
    "            x = self.norm(x)\n",
    "            return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None, view_label=None):\n",
    "        x = self.forward_features(x, cam_label, view_label)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'model' in param_dict:\n",
    "            param_dict = param_dict['model']\n",
    "\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "\n",
    "        for k, v in param_dict.items():\n",
    "            if 'head' in k or 'dist' in k:\n",
    "                continue\n",
    "            if 'patch_embed.proj.weight' in k and len(v.shape) < 4:\n",
    "                # For old models that I trained prior to conv based patchification\n",
    "                O, I, H, W = self.patch_embed.proj.weight.shape\n",
    "                v = v.reshape(O, -1, H, W)\n",
    "            elif k == 'pos_embed' and v.shape != self.pos_embed.shape:\n",
    "                # To resize pos embedding when using model at different size from pretrained weights\n",
    "                if 'distilled' in model_path:\n",
    "                    print('distill need to choose right cls token in the pth')\n",
    "                    v = torch.cat([v[:, 0:1], v[:, 2:]], dim=1)\n",
    "                v = resize_pos_embed(v, self.pos_embed, self.patch_embed.num_y, self.patch_embed.num_x)\n",
    "                # self.state_dict()[k].copy_(revise)\n",
    "            try:\n",
    "                self.state_dict()[k].copy_(v)\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in k :{}: param_dict{} vs self.state_dict(){}'.format(k, v.shape, self.state_dict()[k].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "def resize_pos_embed(posemb, posemb_new, hight, width):\n",
    "    # Rescale the grid of position embeddings when loading from state_dict. Adapted from\n",
    "    # https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224\n",
    "    print('Resized position embedding: %s to %s', posemb.shape, posemb_new.shape)\n",
    "    ntok_new = posemb_new.shape[1]\n",
    "    if True:\n",
    "        posemb_tok, posemb_grid = posemb[:, :1], posemb[0, 1:]\n",
    "        ntok_new -= 1\n",
    "    else:\n",
    "        posemb_tok, posemb_grid = posemb[:, :0], posemb[0]\n",
    "    gs_old = int(math.sqrt(len(posemb_grid)))\n",
    "\n",
    "    print('Position embedding resize to height:{} width: {}'.format(hight, width))\n",
    "    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(0, 3, 1, 2)\n",
    "    posemb_grid = F.interpolate(posemb_grid, size=(hight, width), mode='bilinear')\n",
    "    # posemb_grid = F.interpolate(posemb_grid, size=(width, hight), mode='bilinear')\n",
    "    posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(1, hight * width, -1)\n",
    "    posemb = torch.cat([posemb_tok, posemb_grid], dim=1)\n",
    "    return posemb\n",
    "\n",
    "def _conv_filter(state_dict, patch_size=16):\n",
    "    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n",
    "    out_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if 'patch_embed.proj.weight' in k:\n",
    "            v = v.reshape((v.shape[0], 3, patch_size, patch_size))\n",
    "        out_dict[k] = v\n",
    "    return out_dict\n",
    "\n",
    "def vit_small_patch16_224_TransReID(img_size=(256, 128), stride_size=16, drop_path_rate=0.1, drop_rate=0.0, attn_drop_rate=0.0, local_feature=False, aie_xishu=1.5, **kwargs):\n",
    "    model = TransReID(\n",
    "        img_size=img_size, patch_size=16, stride_size=stride_size, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n",
    "        drop_path_rate=drop_path_rate, drop_rate=drop_rate, attn_drop_rate=attn_drop_rate, aie_xishu=aie_xishu, local_feature=local_feature,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def vit_base_patch16_224_TransReID(img_size=(256, 128), stride_size=16, drop_path_rate=0.1, local_feature=False,aie_xishu=1.5, **kwargs):\n",
    "    model = TransReID(\n",
    "        img_size=img_size, patch_size=16, stride_size=stride_size, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True, drop_path_rate = drop_path_rate,\\\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),  aie_xishu=aie_xishu, local_feature=local_feature, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        print(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    # type: (Tensor, float, float, float, float) -> Tensor\n",
    "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
    "    normal distribution. The values are effectively drawn from the\n",
    "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
    "    with values outside :math:`[a, b]` redrawn until they are within\n",
    "    the bounds. The method used for generating the random values works\n",
    "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        mean: the mean of the normal distribution\n",
    "        std: the standard deviation of the normal distribution\n",
    "        a: the minimum cutoff value\n",
    "        b: the maximum cutoff value\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.trunc_normal_(w)\n",
    "    \"\"\"\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "id": "jMJxg1IHxtLM",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title ViT model create\n",
    "factory_hh = {\n",
    "    'vit_base_patch16_224_TransReID': vit_base_patch16_224_TransReID,\n",
    "    'vit_small_patch16_224_TransReID': vit_small_patch16_224_TransReID,\n",
    "    # 'resnet101': resnet101,\n",
    "}\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight, std=0.001)\n",
    "        if m.bias:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "class build_transformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(build_transformer, self).__init__()\n",
    "        last_stride = 1\n",
    "        #model_path = cfg.MODEL.PRETRAIN_PATH\n",
    "        model_name = \"transformer\"\n",
    "        pretrain_choice = \"imagenet\"\n",
    "        self.cos_layer = False\n",
    "        self.neck = \"bnneck\"\n",
    "        self.neck_feat = \"after\"\n",
    "        self.task_type = \"classify_DA\"\n",
    "        self.in_planes = 384\n",
    "        self.bottleneck_dim = 256\n",
    "        print('using Transformer_type: {} as a backbone'.format(\"vit_small_patch16_224_TransReID\"))\n",
    "\n",
    "        self.base = factory_hh[\"vit_small_patch16_224_TransReID\"](img_size=224, aie_xishu=1.5,local_feature=False, stride_size=[16, 16], drop_path_rate=0.1)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.ID_LOSS_TYPE = \"softmax\"\n",
    "        if self.ID_LOSS_TYPE == 'arcface':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = Arcface(self.in_planes, self.num_classes,\n",
    "                                    s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'cosface':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = Cosface(self.in_planes, self.num_classes,\n",
    "                                    s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'amsoftmax':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = AMSoftmax(self.in_planes, self.num_classes,\n",
    "                                        s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'circle':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE, cfg.SOLVER.COSINE_SCALE, cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = CircleLoss(self.in_planes, self.num_classes,\n",
    "                                        s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.in_planes, self.num_classes, bias=False)\n",
    "            self.classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.bottleneck = nn.BatchNorm1d(self.in_planes)\n",
    "        self.bottleneck.bias.requires_grad_(False)\n",
    "        self.bottleneck.apply(weights_init_kaiming)\n",
    "\n",
    "        #self._load_parameter(pretrain_choice, model_path)\n",
    "\n",
    "    def _load_parameter(self, pretrain_choice, model_path):\n",
    "        if pretrain_choice == 'imagenet':\n",
    "            self.base.load_param(model_path)\n",
    "            print('Loading pretrained ImageNet model......from {}'.format(model_path))\n",
    "        elif pretrain_choice == 'un_pretrain':\n",
    "            self.base.load_un_param(model_path)\n",
    "            print('Loading trans_tune model......from {}'.format(model_path))\n",
    "        elif pretrain_choice == 'pretrain':\n",
    "            self.load_param_finetune(model_path)\n",
    "            print('Loading pretrained model......from {}'.format(model_path))\n",
    "\n",
    "    def forward(self, x, label=None, cam_label= None, view_label=None, return_logits=True):  # label is unused if self.cos_layer == 'no'\n",
    "        global_feat = self.base(x, cam_label=cam_label, view_label=view_label)\n",
    "        feat = self.bottleneck(global_feat)\n",
    "        if return_logits:\n",
    "            if self.cos_layer:\n",
    "                cls_score = self.arcface(feat, label)\n",
    "            else:\n",
    "                cls_score = self.classifier(feat)\n",
    "            return cls_score\n",
    "        elif self.training:\n",
    "            if self.ID_LOSS_TYPE in ('arcface', 'cosface', 'amsoftmax', 'circle'):\n",
    "                cls_score = self.classifier(feat, label)\n",
    "            else:\n",
    "                cls_score = self.classifier(feat)\n",
    "\n",
    "            return cls_score, global_feat  # global feature for triplet loss\n",
    "        else:\n",
    "            if self.neck_feat == 'after':\n",
    "                # print(\"Test with feature after BN\")\n",
    "                return feat\n",
    "            else:\n",
    "                # print(\"Test with feature before BN\")\n",
    "                return global_feat\n",
    "\n",
    "    def load_param(self, param_dict):\n",
    "        #param_dict = torch.load(trained_path)\n",
    "        print(self.state_dict().keys())\n",
    "        print(param_dict.keys())\n",
    "        for i in param_dict:\n",
    "            if 'classifier' in i or 'arcface' in i or 'bottleneck' in i or 'gap' in i:\n",
    "                continue\n",
    "            #self.state_dict()[i.replace('module.', '')].copy_(param_dict[i])\n",
    "            if(i in self.state_dict()):\n",
    "              self.state_dict()[i.replace('base.', '')].copy_(param_dict[i])\n",
    "        #print('Loading pretrained model from {}'.format(trained_path))\n",
    "\n",
    "\n",
    "    def load_param_finetune(self, model_path):\n",
    "        param_dict = torch.load(model_path)\n",
    "        for i in param_dict:\n",
    "            if 'module.' in i: new_i = i.replace('module.','')\n",
    "            else: new_i = i\n",
    "            if new_i not in self.state_dict().keys():\n",
    "                print('model parameter: {} not match'.format(new_i))\n",
    "                continue\n",
    "            self.state_dict()[new_i].copy_(param_dict[i])\n",
    "        print('Loading pretrained model for finetuning from {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "qrIf5jw54xOh",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title mobilenet\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, 1],\n",
    "            [6,  24, 2, 2],\n",
    "            [6,  32, 3, 2],\n",
    "            [6,  64, 4, 2],\n",
    "            [6,  96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenetv2(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNet V2 model\n",
    "    \"\"\"\n",
    "    return MobileNetV2(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCciymuJwjIs",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "7a9404af-2a04-4e32-99b6-fbb9df170867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Transformer_type: vit_small_patch16_224_TransReID as a backbone\n",
      "using stride: [16, 16], and part number is num_y14 * num_x14\n",
      "using drop_path_rate is : 0.1\n",
      "using aie_xishu is : 1.5\n",
      "embed_diim 384 mlp_ratio 4\n",
      "odict_keys(['base.cls_token', 'base.pos_embed', 'base.patch_embed.proj.weight', 'base.patch_embed.proj.bias', 'base.blocks.0.norm1.weight', 'base.blocks.0.norm1.bias', 'base.blocks.0.attn.qkv.weight', 'base.blocks.0.attn.qkv.bias', 'base.blocks.0.attn.proj.weight', 'base.blocks.0.attn.proj.bias', 'base.blocks.0.norm2.weight', 'base.blocks.0.norm2.bias', 'base.blocks.0.mlp.fc1.weight', 'base.blocks.0.mlp.fc1.bias', 'base.blocks.0.mlp.fc2.weight', 'base.blocks.0.mlp.fc2.bias', 'base.blocks.1.norm1.weight', 'base.blocks.1.norm1.bias', 'base.blocks.1.attn.qkv.weight', 'base.blocks.1.attn.qkv.bias', 'base.blocks.1.attn.proj.weight', 'base.blocks.1.attn.proj.bias', 'base.blocks.1.norm2.weight', 'base.blocks.1.norm2.bias', 'base.blocks.1.mlp.fc1.weight', 'base.blocks.1.mlp.fc1.bias', 'base.blocks.1.mlp.fc2.weight', 'base.blocks.1.mlp.fc2.bias', 'base.blocks.2.norm1.weight', 'base.blocks.2.norm1.bias', 'base.blocks.2.attn.qkv.weight', 'base.blocks.2.attn.qkv.bias', 'base.blocks.2.attn.proj.weight', 'base.blocks.2.attn.proj.bias', 'base.blocks.2.norm2.weight', 'base.blocks.2.norm2.bias', 'base.blocks.2.mlp.fc1.weight', 'base.blocks.2.mlp.fc1.bias', 'base.blocks.2.mlp.fc2.weight', 'base.blocks.2.mlp.fc2.bias', 'base.blocks.3.norm1.weight', 'base.blocks.3.norm1.bias', 'base.blocks.3.attn.qkv.weight', 'base.blocks.3.attn.qkv.bias', 'base.blocks.3.attn.proj.weight', 'base.blocks.3.attn.proj.bias', 'base.blocks.3.norm2.weight', 'base.blocks.3.norm2.bias', 'base.blocks.3.mlp.fc1.weight', 'base.blocks.3.mlp.fc1.bias', 'base.blocks.3.mlp.fc2.weight', 'base.blocks.3.mlp.fc2.bias', 'base.blocks.4.norm1.weight', 'base.blocks.4.norm1.bias', 'base.blocks.4.attn.qkv.weight', 'base.blocks.4.attn.qkv.bias', 'base.blocks.4.attn.proj.weight', 'base.blocks.4.attn.proj.bias', 'base.blocks.4.norm2.weight', 'base.blocks.4.norm2.bias', 'base.blocks.4.mlp.fc1.weight', 'base.blocks.4.mlp.fc1.bias', 'base.blocks.4.mlp.fc2.weight', 'base.blocks.4.mlp.fc2.bias', 'base.blocks.5.norm1.weight', 'base.blocks.5.norm1.bias', 'base.blocks.5.attn.qkv.weight', 'base.blocks.5.attn.qkv.bias', 'base.blocks.5.attn.proj.weight', 'base.blocks.5.attn.proj.bias', 'base.blocks.5.norm2.weight', 'base.blocks.5.norm2.bias', 'base.blocks.5.mlp.fc1.weight', 'base.blocks.5.mlp.fc1.bias', 'base.blocks.5.mlp.fc2.weight', 'base.blocks.5.mlp.fc2.bias', 'base.blocks.6.norm1.weight', 'base.blocks.6.norm1.bias', 'base.blocks.6.attn.qkv.weight', 'base.blocks.6.attn.qkv.bias', 'base.blocks.6.attn.proj.weight', 'base.blocks.6.attn.proj.bias', 'base.blocks.6.norm2.weight', 'base.blocks.6.norm2.bias', 'base.blocks.6.mlp.fc1.weight', 'base.blocks.6.mlp.fc1.bias', 'base.blocks.6.mlp.fc2.weight', 'base.blocks.6.mlp.fc2.bias', 'base.blocks.7.norm1.weight', 'base.blocks.7.norm1.bias', 'base.blocks.7.attn.qkv.weight', 'base.blocks.7.attn.qkv.bias', 'base.blocks.7.attn.proj.weight', 'base.blocks.7.attn.proj.bias', 'base.blocks.7.norm2.weight', 'base.blocks.7.norm2.bias', 'base.blocks.7.mlp.fc1.weight', 'base.blocks.7.mlp.fc1.bias', 'base.blocks.7.mlp.fc2.weight', 'base.blocks.7.mlp.fc2.bias', 'base.blocks.8.norm1.weight', 'base.blocks.8.norm1.bias', 'base.blocks.8.attn.qkv.weight', 'base.blocks.8.attn.qkv.bias', 'base.blocks.8.attn.proj.weight', 'base.blocks.8.attn.proj.bias', 'base.blocks.8.norm2.weight', 'base.blocks.8.norm2.bias', 'base.blocks.8.mlp.fc1.weight', 'base.blocks.8.mlp.fc1.bias', 'base.blocks.8.mlp.fc2.weight', 'base.blocks.8.mlp.fc2.bias', 'base.blocks.9.norm1.weight', 'base.blocks.9.norm1.bias', 'base.blocks.9.attn.qkv.weight', 'base.blocks.9.attn.qkv.bias', 'base.blocks.9.attn.proj.weight', 'base.blocks.9.attn.proj.bias', 'base.blocks.9.norm2.weight', 'base.blocks.9.norm2.bias', 'base.blocks.9.mlp.fc1.weight', 'base.blocks.9.mlp.fc1.bias', 'base.blocks.9.mlp.fc2.weight', 'base.blocks.9.mlp.fc2.bias', 'base.blocks.10.norm1.weight', 'base.blocks.10.norm1.bias', 'base.blocks.10.attn.qkv.weight', 'base.blocks.10.attn.qkv.bias', 'base.blocks.10.attn.proj.weight', 'base.blocks.10.attn.proj.bias', 'base.blocks.10.norm2.weight', 'base.blocks.10.norm2.bias', 'base.blocks.10.mlp.fc1.weight', 'base.blocks.10.mlp.fc1.bias', 'base.blocks.10.mlp.fc2.weight', 'base.blocks.10.mlp.fc2.bias', 'base.blocks.11.norm1.weight', 'base.blocks.11.norm1.bias', 'base.blocks.11.attn.qkv.weight', 'base.blocks.11.attn.qkv.bias', 'base.blocks.11.attn.proj.weight', 'base.blocks.11.attn.proj.bias', 'base.blocks.11.norm2.weight', 'base.blocks.11.norm2.bias', 'base.blocks.11.mlp.fc1.weight', 'base.blocks.11.mlp.fc1.bias', 'base.blocks.11.mlp.fc2.weight', 'base.blocks.11.mlp.fc2.bias', 'base.norm.weight', 'base.norm.bias', 'base.fc.weight', 'base.fc.bias', 'classifier.weight', 'bottleneck.weight', 'bottleneck.bias', 'bottleneck.running_mean', 'bottleneck.running_var', 'bottleneck.num_batches_tracked'])\n",
      "odict_keys(['dist_token', 'cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'head_dist.weight', 'head_dist.bias'])\n"
     ]
    }
   ],
   "source": [
    "ViT = build_transformer(num_classes = 5)\n",
    "state_dict = load_state_dict_from_url(\"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\", progress=True)\n",
    "ViT.load_param(state_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "form",
    "id": "4fcdcd5f"
   },
   "outputs": [],
   "source": [
    "#@title Train Function\n",
    "def train_model_classification(\n",
    "    model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=25, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        running_res = []\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            count_3 = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            print(\"expecting data\")\n",
    "            running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            for (inputs,wt_l), labels in tqdm(dataloaders[phase]):\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                wt_l = wt_l.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == \"train\":\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        #outputs, aux_outputs = model(inputs, wt_l)\n",
    "                        outputs = model(wt_l)#inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        \n",
    "                        #loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 #+ 0.4 * loss2\n",
    "                    else:\n",
    "                        #outputs = model(inputs)#, wt_l)\n",
    "                        outputs = model(wt_l)#, wt_l)\n",
    "                        outputs = torch.squeeze(outputs)\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                # statistics\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                for i in range(0, len(preds)):\n",
    "                    if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                        count_3 += 1\n",
    "\n",
    "                    if preds[i] == labels.data[i]:\n",
    "                        running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "                    running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            print(running_total)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = 100.0 * running_corrects / len(dataloaders[phase].dataset)\n",
    "            running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "            print(running_res)\n",
    "\n",
    "            print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "                best_train_acc = epoch_acc\n",
    "                training_res = running_res.copy()\n",
    "\n",
    "            if phase == \"val\" and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                res = running_res.copy()\n",
    "                torch.save(model.state_dict(), 'F:/Scales/inception_v3_classification_image_only_temp.pth')\n",
    "\n",
    "            if phase == \"val\":\n",
    "                loss_list.append(epoch_loss)\n",
    "                acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [model, loss_list, acc_list, res, training_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title simplenet\n",
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(3, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, input):\n",
    "        f1 = F.relu(self.fc1(input))\n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        f3 = self.fc3(f2)\n",
    "        \n",
    "        return f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:633: UserWarning: Overwriting tiny_vit_5m_224 in registry with __main__.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_5m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:646: UserWarning: Overwriting tiny_vit_11m_224 in registry with __main__.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_11m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:659: UserWarning: Overwriting tiny_vit_21m_224 in registry with __main__.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:672: UserWarning: Overwriting tiny_vit_21m_384 in registry with __main__.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_384(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:686: UserWarning: Overwriting tiny_vit_21m_512 in registry with __main__.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_512(pretrained=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "#@title TinyVit\n",
    "import itertools\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import timm\n",
    "from timm.models.layers import DropPath as TimmDropPath,\\\n",
    "    to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "try:\n",
    "    # timm.__version__ >= \"0.6\"\n",
    "    from timm.models._builder import build_model_with_cfg\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    # timm.__version__ < \"0.6\"\n",
    "    from timm.models.helpers import build_model_with_cfg\n",
    "\n",
    "\n",
    "class Conv2d_BN(torch.nn.Sequential):\n",
    "    def __init__(self, a, b, ks=1, stride=1, pad=0, dilation=1,\n",
    "                 groups=1, bn_weight_init=1):\n",
    "        super().__init__()\n",
    "        self.add_module('c', torch.nn.Conv2d(\n",
    "            a, b, ks, stride, pad, dilation, groups, bias=False))\n",
    "        bn = torch.nn.BatchNorm2d(b)\n",
    "        torch.nn.init.constant_(bn.weight, bn_weight_init)\n",
    "        torch.nn.init.constant_(bn.bias, 0)\n",
    "        self.add_module('bn', bn)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fuse(self):\n",
    "        c, bn = self._modules.values()\n",
    "        w = bn.weight / (bn.running_var + bn.eps)**0.5\n",
    "        w = c.weight * w[:, None, None, None]\n",
    "        b = bn.bias - bn.running_mean * bn.weight / \\\n",
    "            (bn.running_var + bn.eps)**0.5\n",
    "        m = torch.nn.Conv2d(w.size(1) * self.c.groups, w.size(\n",
    "            0), w.shape[2:], stride=self.c.stride, padding=self.c.padding, dilation=self.c.dilation, groups=self.c.groups)\n",
    "        m.weight.data.copy_(w)\n",
    "        m.bias.data.copy_(b)\n",
    "        return m\n",
    "\n",
    "\n",
    "class DropPath(TimmDropPath):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super().__init__(drop_prob=drop_prob)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def __repr__(self):\n",
    "        msg = super().__repr__()\n",
    "        msg += f'(drop_prob={self.drop_prob})'\n",
    "        return msg\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_chans, embed_dim, resolution, activation):\n",
    "        super().__init__()\n",
    "        img_size: Tuple[int, int] = to_2tuple(resolution)\n",
    "        self.patches_resolution = (img_size[0] // 4, img_size[1] // 4)\n",
    "        self.num_patches = self.patches_resolution[0] * \\\n",
    "            self.patches_resolution[1]\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        n = embed_dim\n",
    "        self.seq = nn.Sequential(\n",
    "            Conv2d_BN(in_chans, n // 2, 3, 2, 1),\n",
    "            activation(),\n",
    "            Conv2d_BN(n // 2, n, 3, 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, expand_ratio,\n",
    "                 activation, drop_path):\n",
    "        super().__init__()\n",
    "        self.in_chans = in_chans\n",
    "        self.hidden_chans = int(in_chans * expand_ratio)\n",
    "        self.out_chans = out_chans\n",
    "\n",
    "        self.conv1 = Conv2d_BN(in_chans, self.hidden_chans, ks=1)\n",
    "        self.act1 = activation()\n",
    "\n",
    "        self.conv2 = Conv2d_BN(self.hidden_chans, self.hidden_chans,\n",
    "                               ks=3, stride=1, pad=1, groups=self.hidden_chans)\n",
    "        self.act2 = activation()\n",
    "\n",
    "        self.conv3 = Conv2d_BN(\n",
    "            self.hidden_chans, out_chans, ks=1, bn_weight_init=0.0)\n",
    "        self.act3 = activation()\n",
    "\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = self.drop_path(x)\n",
    "\n",
    "        x += shortcut\n",
    "        x = self.act3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, input_resolution, dim, out_dim, activation):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim\n",
    "        self.act = activation()\n",
    "        self.conv1 = Conv2d_BN(dim, out_dim, 1, 1, 0)\n",
    "        self.conv2 = Conv2d_BN(out_dim, out_dim, 3, 2, 1, groups=out_dim)\n",
    "        self.conv3 = Conv2d_BN(out_dim, out_dim, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 3:\n",
    "            H, W = self.input_resolution\n",
    "            B = len(x)\n",
    "            # (B, C, H, W)\n",
    "            x = x.view(B, H, W, -1).permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, depth,\n",
    "                 activation,\n",
    "                 drop_path=0., downsample=None, use_checkpoint=False,\n",
    "                 out_dim=None,\n",
    "                 conv_expand_ratio=4.,\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            MBConv(dim, dim, conv_expand_ratio, activation,\n",
    "                   drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                   )\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(\n",
    "                input_resolution, dim=dim, out_dim=out_dim, activation=activation)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None,\n",
    "                 out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.norm = nn.LayerNorm(in_features)\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.act = act_layer()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, dim, key_dim, num_heads=8,\n",
    "                 attn_ratio=4,\n",
    "                 resolution=(14, 14),\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # (h, w)\n",
    "        assert isinstance(resolution, tuple) and len(resolution) == 2\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = key_dim ** -0.5\n",
    "        self.key_dim = key_dim\n",
    "        self.nh_kd = nh_kd = key_dim * num_heads\n",
    "        self.d = int(attn_ratio * key_dim)\n",
    "        self.dh = int(attn_ratio * key_dim) * num_heads\n",
    "        self.attn_ratio = attn_ratio\n",
    "        h = self.dh + nh_kd * 2\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.qkv = nn.Linear(dim, h)\n",
    "        self.proj = nn.Linear(self.dh, dim)\n",
    "\n",
    "        points = list(itertools.product(\n",
    "            range(resolution[0]), range(resolution[1])))\n",
    "        N = len(points)\n",
    "        attention_offsets = {}\n",
    "        idxs = []\n",
    "        for p1 in points:\n",
    "            for p2 in points:\n",
    "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
    "                if offset not in attention_offsets:\n",
    "                    attention_offsets[offset] = len(attention_offsets)\n",
    "                idxs.append(attention_offsets[offset])\n",
    "        self.attention_biases = torch.nn.Parameter(\n",
    "            torch.zeros(num_heads, len(attention_offsets)))\n",
    "        self.register_buffer('attention_bias_idxs',\n",
    "                             torch.LongTensor(idxs).view(N, N),\n",
    "                             persistent=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        if mode and hasattr(self, 'ab'):\n",
    "            del self.ab\n",
    "        else:\n",
    "            self.ab = self.attention_biases[:, self.attention_bias_idxs]\n",
    "\n",
    "    def forward(self, x):  # x (B,N,C)\n",
    "        B, N, _ = x.shape\n",
    "\n",
    "        # Normalization\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.qkv(x)\n",
    "        # (B, N, num_heads, d)\n",
    "        q, k, v = qkv.view(B, N, self.num_heads, -\n",
    "                           1).split([self.key_dim, self.key_dim, self.d], dim=3)\n",
    "        # (B, num_heads, N, d)\n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        k = k.permute(0, 2, 1, 3)\n",
    "        v = v.permute(0, 2, 1, 3)\n",
    "\n",
    "        attn = (\n",
    "            (q @ k.transpose(-2, -1)) * self.scale\n",
    "            +\n",
    "            (self.attention_biases[:, self.attention_bias_idxs]\n",
    "             if self.training else self.ab)\n",
    "        )\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, self.dh)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TinyViTBlock(nn.Module):\n",
    "    r\"\"\" TinyViT Block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int, int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        local_conv_size (int): the kernel size of the convolution between\n",
    "                               Attention and MLP. Default: 3\n",
    "        activation: the activation function. Default: nn.GELU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7,\n",
    "                 mlp_ratio=4., drop=0., drop_path=0.,\n",
    "                 local_conv_size=3,\n",
    "                 activation=nn.GELU,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        assert window_size > 0, 'window_size must be greater than 0'\n",
    "        self.window_size = window_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        assert dim % num_heads == 0, 'dim must be divisible by num_heads'\n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "        window_resolution = (window_size, window_size)\n",
    "        self.attn = Attention(dim, head_dim, num_heads,\n",
    "                              attn_ratio=1, resolution=window_resolution)\n",
    "\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        mlp_activation = activation\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
    "                       act_layer=mlp_activation, drop=drop)\n",
    "\n",
    "        pad = local_conv_size // 2\n",
    "        self.local_conv = Conv2d_BN(\n",
    "            dim, dim, ks=local_conv_size, stride=1, pad=pad, groups=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        res_x = x\n",
    "        if H == self.window_size and W == self.window_size:\n",
    "            x = self.attn(x)\n",
    "        else:\n",
    "            x = x.view(B, H, W, C)\n",
    "            pad_b = (self.window_size - H %\n",
    "                     self.window_size) % self.window_size\n",
    "            pad_r = (self.window_size - W %\n",
    "                     self.window_size) % self.window_size\n",
    "            padding = pad_b > 0 or pad_r > 0\n",
    "\n",
    "            if padding:\n",
    "                x = F.pad(x, (0, 0, 0, pad_r, 0, pad_b))\n",
    "\n",
    "            pH, pW = H + pad_b, W + pad_r\n",
    "            nH = pH // self.window_size\n",
    "            nW = pW // self.window_size\n",
    "            # window partition\n",
    "            x = x.view(B, nH, self.window_size, nW, self.window_size, C).transpose(2, 3).reshape(\n",
    "                B * nH * nW, self.window_size * self.window_size, C\n",
    "            )\n",
    "            x = self.attn(x)\n",
    "            # window reverse\n",
    "            x = x.view(B, nH, nW, self.window_size, self.window_size,\n",
    "                       C).transpose(2, 3).reshape(B, pH, pW, C)\n",
    "\n",
    "            if padding:\n",
    "                x = x[:, :H, :W].contiguous()\n",
    "\n",
    "            x = x.view(B, L, C)\n",
    "\n",
    "        x = res_x + self.drop_path(x)\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "        x = self.local_conv(x)\n",
    "        x = x.view(B, C, L).transpose(1, 2)\n",
    "\n",
    "        x = x + self.drop_path(self.mlp(x))\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic TinyViT layer for one stage.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "        local_conv_size: the kernel size of the depthwise convolution between attention and MLP. Default: 3\n",
    "        activation: the activation function. Default: nn.GELU\n",
    "        out_dim: the output dimension of the layer. Default: dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., drop=0.,\n",
    "                 drop_path=0., downsample=None, use_checkpoint=False,\n",
    "                 local_conv_size=3,\n",
    "                 activation=nn.GELU,\n",
    "                 out_dim=None,\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TinyViTBlock(dim=dim, input_resolution=input_resolution,\n",
    "                         num_heads=num_heads, window_size=window_size,\n",
    "                         mlp_ratio=mlp_ratio,\n",
    "                         drop=drop,\n",
    "                         drop_path=drop_path[i] if isinstance(\n",
    "                             drop_path, list) else drop_path,\n",
    "                         local_conv_size=local_conv_size,\n",
    "                         activation=activation,\n",
    "                         )\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(\n",
    "                input_resolution, dim=dim, out_dim=out_dim, activation=activation)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "\n",
    "class TinyViT(nn.Module):\n",
    "    def __init__(self, img_size=224, in_chans=3, num_classes=1000,\n",
    "                 embed_dims=[96, 192, 384, 768], depths=[2, 2, 6, 2],\n",
    "                 num_heads=[3, 6, 12, 24],\n",
    "                 window_sizes=[7, 7, 14, 7],\n",
    "                 mlp_ratio=4.,\n",
    "                 drop_rate=0.,\n",
    "                 drop_path_rate=0.1,\n",
    "                 use_checkpoint=False,\n",
    "                 mbconv_expand_ratio=4.0,\n",
    "                 local_conv_size=3,\n",
    "                 layer_lr_decay=1.0,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "        self.num_layers = len(depths)\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        activation = nn.GELU\n",
    "\n",
    "        self.patch_embed = PatchEmbed(in_chans=in_chans,\n",
    "                                      embed_dim=embed_dims[0],\n",
    "                                      resolution=img_size,\n",
    "                                      activation=activation)\n",
    "\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate,\n",
    "                                                sum(depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            kwargs = dict(dim=embed_dims[i_layer],\n",
    "                          input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                            patches_resolution[1] // (2 ** i_layer)),\n",
    "                          depth=depths[i_layer],\n",
    "                          drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                          downsample=PatchMerging if (\n",
    "                              i_layer < self.num_layers - 1) else None,\n",
    "                          use_checkpoint=use_checkpoint,\n",
    "                          out_dim=embed_dims[min(\n",
    "                              i_layer + 1, len(embed_dims) - 1)],\n",
    "                          activation=activation,\n",
    "                          )\n",
    "            if i_layer == 0:\n",
    "                layer = ConvLayer(\n",
    "                    conv_expand_ratio=mbconv_expand_ratio,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            else:\n",
    "                layer = BasicLayer(\n",
    "                    num_heads=num_heads[i_layer],\n",
    "                    window_size=window_sizes[i_layer],\n",
    "                    mlp_ratio=self.mlp_ratio,\n",
    "                    drop=drop_rate,\n",
    "                    local_conv_size=local_conv_size,\n",
    "                    **kwargs)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # Classifier head\n",
    "        self.norm_head = nn.LayerNorm(embed_dims[-1])\n",
    "        self.head = nn.Linear(\n",
    "            embed_dims[-1], num_classes) if num_classes > 0 else torch.nn.Identity()\n",
    "\n",
    "        # init weights\n",
    "        self.apply(self._init_weights)\n",
    "        self.set_layer_lr_decay(layer_lr_decay)\n",
    "\n",
    "    def set_layer_lr_decay(self, layer_lr_decay):\n",
    "        decay_rate = layer_lr_decay\n",
    "\n",
    "        # layers -> blocks (depth)\n",
    "        depth = sum(self.depths)\n",
    "        lr_scales = [decay_rate ** (depth - i - 1) for i in range(depth)]\n",
    "\n",
    "        def _set_lr_scale(m, scale):\n",
    "            for p in m.parameters():\n",
    "                p.lr_scale = scale\n",
    "\n",
    "        self.patch_embed.apply(lambda x: _set_lr_scale(x, lr_scales[0]))\n",
    "        i = 0\n",
    "        for layer in self.layers:\n",
    "            for block in layer.blocks:\n",
    "                block.apply(lambda x: _set_lr_scale(x, lr_scales[i]))\n",
    "                i += 1\n",
    "            if layer.downsample is not None:\n",
    "                layer.downsample.apply(\n",
    "                    lambda x: _set_lr_scale(x, lr_scales[i - 1]))\n",
    "        assert i == depth\n",
    "        for m in [self.norm_head, self.head]:\n",
    "            m.apply(lambda x: _set_lr_scale(x, lr_scales[-1]))\n",
    "\n",
    "        for k, p in self.named_parameters():\n",
    "            p.param_name = k\n",
    "\n",
    "        def _check_lr_scale(m):\n",
    "            for p in m.parameters():\n",
    "                assert hasattr(p, 'lr_scale'), p.param_name\n",
    "\n",
    "        self.apply(_check_lr_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'attention_biases'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # x: (N, C, H, W)\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        x = self.layers[0](x)\n",
    "        start_i = 1\n",
    "\n",
    "        for i in range(start_i, len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.mean(1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.norm_head(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "_checkpoint_url_format = \\\n",
    "    'https://github.com/wkcn/TinyViT-model-zoo/releases/download/checkpoints/{}.pth'\n",
    "\n",
    "\n",
    "def _create_tiny_vit(variant, pretrained=False, **kwargs):\n",
    "    # pretrained_type: 22kto1k_distill, 1k, 22k_distill\n",
    "    pretrained_type = kwargs.pop('pretrained_type', '22kto1k_distill')\n",
    "    assert pretrained_type in ['22kto1k_distill', '1k', '22k_distill'], \\\n",
    "        'pretrained_type should be one of 22kto1k_distill, 1k, 22k_distill'\n",
    "\n",
    "    img_size = kwargs.get('img_size', 224)\n",
    "    if img_size != 224:\n",
    "        pretrained_type = pretrained_type.replace('_', f'_{img_size}_')\n",
    "\n",
    "    num_classes_pretrained = 21841 if \\\n",
    "        pretrained_type  == '22k_distill' else 1000\n",
    "\n",
    "    variant_without_img_size = '_'.join(variant.split('_')[:-1])\n",
    "    cfg = dict(\n",
    "        url=_checkpoint_url_format.format(\n",
    "            f'{variant_without_img_size}_{pretrained_type}'),\n",
    "        num_classes=num_classes_pretrained,\n",
    "        classifier='head',\n",
    "    )\n",
    "\n",
    "    def _pretrained_filter_fn(state_dict):\n",
    "        state_dict = state_dict['model']\n",
    "        # filter out attention_bias_idxs\n",
    "        state_dict = {k: v for k, v in state_dict.items() if \\\n",
    "            not k.endswith('attention_bias_idxs')}\n",
    "        return state_dict\n",
    "\n",
    "    if timm.__version__ >= \"0.6\":\n",
    "        return build_model_with_cfg(\n",
    "            TinyViT, variant, pretrained,\n",
    "            pretrained_cfg=cfg,\n",
    "            pretrained_filter_fn=_pretrained_filter_fn,\n",
    "            **kwargs)\n",
    "    else:\n",
    "        return build_model_with_cfg(\n",
    "            TinyViT, variant, pretrained,\n",
    "            default_cfg=cfg,\n",
    "            pretrained_filter_fn=_pretrained_filter_fn,\n",
    "            **kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_5m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[64, 128, 160, 320],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[2, 4, 5, 10],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.0,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_5m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_11m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[64, 128, 256, 448],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[2, 4, 8, 14],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_11m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.2,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_384(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        img_size=384,\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[12, 12, 24, 12],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_384', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_512(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        img_size=512,\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[16, 16, 32, 16],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_512', pretrained, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24357354\n",
      "11179077\n",
      "27523199\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models.vision_transformer\n",
    "model = torchvision.models.inception_v3(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = torchvision.models.resnet18(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "def _vision_transformer(\n",
    "    patch_size: int,\n",
    "    num_layers: int,\n",
    "    num_heads: int,\n",
    "    hidden_dim: int,\n",
    "    mlp_dim: int,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> VisionTransformer:\n",
    "    image_size = kwargs.pop(\"image_size\", 224)\n",
    "\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        hidden_dim=hidden_dim,\n",
    "        mlp_dim=mlp_dim,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def vit_t_16(*, weights = None, progress: bool = True, **kwargs: Any) -> VisionTransformer:\n",
    "    \"\"\"\n",
    "    Constructs a vit_l_16 architecture from\n",
    "    `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale <https://arxiv.org/abs/2010.11929>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.ViT_L_16_Weights`, optional): The pretrained\n",
    "            weights to use. See :class:`~torchvision.models.ViT_L_16_Weights`\n",
    "            below for more details and possible values. By default, no pre-trained weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vision_transformer.VisionTransformer``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.ViT_L_16_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    kwargs[image_size] = \"224\"\n",
    "    return _vision_transformer(\n",
    "        patch_size=16,\n",
    "        num_layers=4,\n",
    "        num_heads=12,\n",
    "        hidden_dim=768,\n",
    "        mlp_dim=3072,\n",
    "        progress=progress,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "#model = vit_t_16(weights = None)\n",
    "#print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "#model = tiny_vit_21m_224()\n",
    "#print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14cc7597",
    "outputId": "a7219c2e-c03a-4fb4-b142-3ecc665414dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2059024522.py:78: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 89.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[0.0, 91.38461538461539, 86.90582959641256, 20.489296636085626, 24.56140350877193]\n",
      "train Loss: 0.7587 Average Accuracy: 76.9670\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 99.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[0.0, 96.9298245614035, 81.86813186813187, 52.27272727272727, 2.6315789473684212]\n",
      "val Loss: 0.5120 Average Accuracy: 78.9579\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 88.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[0.0, 94.71458773784356, 81.18811881188118, 60.204081632653065, 7.936507936507937]\n",
      "test Loss: 0.5175 Average Accuracy: 78.3868\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 83.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[76.08695652173913, 95.2, 86.3677130044843, 36.69724770642202, 50.292397660818715]\n",
      "train Loss: 0.4191 Average Accuracy: 83.6637\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 99.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 20.454545454545453, 47.36842105263158]\n",
      "val Loss: 0.4478 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 103.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 88.11881188118812, 29.591836734693878, 57.142857142857146]\n",
      "test Loss: 0.4464 Average Accuracy: 83.2472\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 96.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[97.82608695652173, 95.01538461538462, 87.08520179372198, 39.75535168195719, 59.06432748538012]\n",
      "train Loss: 0.3883 Average Accuracy: 85.1652\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 20.454545454545453, 50.0]\n",
      "val Loss: 0.4362 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 87.7887788778878, 36.734693877551024, 61.904761904761905]\n",
      "test Loss: 0.4295 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 86.18834080717488, 44.342507645259936, 57.30994152046784]\n",
      "train Loss: 0.3803 Average Accuracy: 85.1652\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 40.90909090909091, 42.10526315789474]\n",
      "val Loss: 0.4405 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.79867986798679, 47.95918367346939, 46.03174603174603]\n",
      "test Loss: 0.4239 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.46153846153847, 87.17488789237669, 44.03669724770642, 62.57309941520468]\n",
      "train Loss: 0.3737 Average Accuracy: 85.5856\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.80701754385964, 80.76923076923077, 22.727272727272727, 47.36842105263158]\n",
      "val Loss: 0.4597 Average Accuracy: 81.1623\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 101.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 95.34883720930233, 82.50825082508251, 37.755102040816325, 55.55555555555556]\n",
      "test Loss: 0.4314 Average Accuracy: 82.9369\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.3542600896861, 44.342507645259936, 59.64912280701754]\n",
      "train Loss: 0.3708 Average Accuracy: 85.7357\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 90.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 84.06593406593407, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4340 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 91.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.46864686468646, 47.95918367346939, 49.20634920634921]\n",
      "test Loss: 0.4119 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 88.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 86.99551569506727, 46.788990825688074, 60.23391812865497]\n",
      "train Loss: 0.3676 Average Accuracy: 85.7958\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4279 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 102.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 52.04081632653061, 50.79365079365079]\n",
      "test Loss: 0.4179 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 86.54708520179372, 45.56574923547401, 60.8187134502924]\n",
      "train Loss: 0.3678 Average Accuracy: 85.6456\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 93.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 85.16483516483517, 40.90909090909091, 44.73684210526316]\n",
      "val Loss: 0.4343 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 98.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.46864686468646, 50.0, 44.44444444444444]\n",
      "test Loss: 0.4135 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 85.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 86.54708520179372, 47.706422018348626, 61.98830409356725]\n",
      "train Loss: 0.3644 Average Accuracy: 85.9159\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 80.21978021978022, 36.36363636363637, 50.0]\n",
      "val Loss: 0.4342 Average Accuracy: 82.1643\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.71458773784356, 82.17821782178218, 50.0, 58.73015873015873]\n",
      "test Loss: 0.4117 Average Accuracy: 83.9710\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 83.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.07692307692308, 86.00896860986548, 46.48318042813456, 63.74269005847953]\n",
      "train Loss: 0.3629 Average Accuracy: 85.7958\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 93.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 89.01098901098901, 22.727272727272727, 44.73684210526316]\n",
      "val Loss: 0.4403 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 90.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 90.0990099009901, 32.6530612244898, 47.61904761904762]\n",
      "test Loss: 0.4223 Average Accuracy: 83.5574\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.4439461883408, 47.400611620795104, 61.98830409356725]\n",
      "train Loss: 0.3649 Average Accuracy: 86.1862\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.91208791208791, 36.36363636363637, 44.73684210526316]\n",
      "val Loss: 0.4293 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 113.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 87.45874587458746, 47.95918367346939, 42.857142857142854]\n",
      "test Loss: 0.4171 Average Accuracy: 83.3506\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 89.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 86.63677130044843, 46.48318042813456, 61.98830409356725]\n",
      "train Loss: 0.3641 Average Accuracy: 85.7658\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 90.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 95.6140350877193, 87.91208791208791, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4218 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 88.11881188118812, 39.795918367346935, 60.317460317460316]\n",
      "test Loss: 0.4183 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.46153846153847, 87.4439461883408, 45.56574923547401, 65.49707602339181]\n",
      "train Loss: 0.3609 Average Accuracy: 85.9760\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 81.86813186813187, 40.90909090909091, 50.0]\n",
      "val Loss: 0.4307 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 114.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.446088794926, 82.17821782178218, 50.0, 58.73015873015873]\n",
      "test Loss: 0.4132 Average Accuracy: 83.3506\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 90.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.01538461538462, 86.00896860986548, 46.48318042813456, 63.74269005847953]\n",
      "train Loss: 0.3592 Average Accuracy: 85.7658\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 88.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 91.20879120879121, 34.09090909090909, 34.21052631578947]\n",
      "val Loss: 0.4419 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 95.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.38900634249471, 91.74917491749174, 42.857142857142854, 39.682539682539684]\n",
      "test Loss: 0.4303 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 78.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 86.63677130044843, 47.400611620795104, 61.40350877192982]\n",
      "train Loss: 0.3589 Average Accuracy: 85.8559\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 84.61538461538461, 29.545454545454547, 42.10526315789474]\n",
      "val Loss: 0.4403 Average Accuracy: 82.5651\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 88.44884488448845, 43.87755102040816, 42.857142857142854]\n",
      "test Loss: 0.4212 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.13846153846154, 86.72645739910314, 42.813455657492355, 61.40350877192982]\n",
      "train Loss: 0.3592 Average Accuracy: 85.5856\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 91.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 89.01098901098901, 29.545454545454547, 44.73684210526316]\n",
      "val Loss: 0.4262 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 101.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 50.79365079365079]\n",
      "test Loss: 0.4191 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.3542600896861, 44.03669724770642, 65.49707602339181]\n",
      "train Loss: 0.3582 Average Accuracy: 86.0060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 95.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.80701754385964, 81.86813186813187, 36.36363636363637, 50.0]\n",
      "val Loss: 0.4331 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 109.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 84.48844884488449, 50.0, 49.20634920634921]\n",
      "test Loss: 0.4093 Average Accuracy: 83.6608\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.07692307692308, 86.99551569506727, 49.235474006116206, 63.1578947368421]\n",
      "train Loss: 0.3504 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4191 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 86.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 87.62331838565022, 47.09480122324159, 66.08187134502924]\n",
      "train Loss: 0.3490 Average Accuracy: 86.3363\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 83.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4194 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 82.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.23467230443974, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 79.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.64615384615385, 87.80269058295964, 46.48318042813456, 67.25146198830409]\n",
      "train Loss: 0.3482 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 106.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 84.06593406593407, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4256 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 93.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 86.13861386138613, 47.95918367346939, 52.38095238095238]\n",
      "test Loss: 0.4054 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.13846153846154, 87.4439461883408, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3472 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 92.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 89.01098901098901, 27.272727272727273, 44.73684210526316]\n",
      "val Loss: 0.4229 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 111.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 50.79365079365079]\n",
      "test Loss: 0.4138 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 89.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.80269058295964, 46.17737003058104, 68.42105263157895]\n",
      "train Loss: 0.3482 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.91208791208791, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4199 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 89.10891089108911, 46.93877551020408, 52.38095238095238]\n",
      "test Loss: 0.4084 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 91.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.80269058295964, 47.09480122324159, 66.66666666666667]\n",
      "train Loss: 0.3475 Average Accuracy: 86.4565\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 88.46153846153847, 31.818181818181817, 44.73684210526316]\n",
      "val Loss: 0.4228 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 89.76897689768977, 45.91836734693877, 49.20634920634921]\n",
      "test Loss: 0.4099 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 96.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 45.87155963302752, 64.91228070175438]\n",
      "train Loss: 0.3482 Average Accuracy: 86.3363\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 91.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 31.818181818181817, 44.73684210526316]\n",
      "val Loss: 0.4226 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.23467230443974, 88.44884488448845, 43.87755102040816, 52.38095238095238]\n",
      "test Loss: 0.4069 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 91.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 44.95412844036697, 67.25146198830409]\n",
      "train Loss: 0.3473 Average Accuracy: 86.3964\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 115.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 82.96703296703296, 40.90909090909091, 50.0]\n",
      "val Loss: 0.4232 Average Accuracy: 83.3667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 105.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 83.82838283828383, 53.06122448979592, 58.73015873015873]\n",
      "test Loss: 0.4063 Average Accuracy: 83.9710\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3478 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4222 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 112.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.44884488448845, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4078 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 98.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 45.87155963302752, 67.25146198830409]\n",
      "train Loss: 0.3468 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 109.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 84.06593406593407, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4229 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.446088794926, 84.81848184818482, 53.06122448979592, 52.38095238095238]\n",
      "test Loss: 0.4059 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.80269058295964, 48.62385321100918, 63.74269005847953]\n",
      "train Loss: 0.3480 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4166 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 41.83673469387755, 60.317460317460316]\n",
      "test Loss: 0.4051 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.62331838565022, 47.400611620795104, 67.83625730994152]\n",
      "train Loss: 0.3472 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 44.73684210526316]\n",
      "val Loss: 0.4213 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 86.46864686468646, 54.08163265306123, 50.79365079365079]\n",
      "test Loss: 0.4080 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 99.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.89237668161435, 45.87155963302752, 67.83625730994152]\n",
      "train Loss: 0.3468 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 115.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 86.81318681318682, 36.36363636363637, 44.73684210526316]\n",
      "val Loss: 0.4196 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 88.11881188118812, 47.95918367346939, 50.79365079365079]\n",
      "test Loss: 0.4093 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 99.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.53363228699551, 49.54128440366973, 64.32748538011695]\n",
      "train Loss: 0.3469 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 113.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 88.46153846153847, 27.272727272727273, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 57.142857142857146]\n",
      "test Loss: 0.4117 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 87.98206278026906, 44.64831804281346, 69.00584795321637]\n",
      "train Loss: 0.3476 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4210 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 48.97959183673469, 50.79365079365079]\n",
      "test Loss: 0.4072 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 66.66666666666667]\n",
      "train Loss: 0.3470 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 85.71428571428571, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4216 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.12871287128714, 51.02040816326531, 52.38095238095238]\n",
      "test Loss: 0.4055 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 99.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.71300448430493, 51.07033639143731, 62.57309941520468]\n",
      "train Loss: 0.3464 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4173 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 114.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 44.89795918367347, 58.73015873015873]\n",
      "test Loss: 0.4052 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 99.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 45.56574923547401, 68.42105263157895]\n",
      "train Loss: 0.3446 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 114.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.4304932735426, 45.87155963302752, 68.42105263157895]\n",
      "train Loss: 0.3443 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 113.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4063 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 88.4304932735426, 48.318042813455655, 64.91228070175438]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 94.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 46.788990825688074, 67.25146198830409]\n",
      "train Loss: 0.3442 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 110.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 111.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4053 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 85.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.01223241590214, 68.42105263157895]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 109.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 112.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4061 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 47.09480122324159, 67.83625730994152]\n",
      "train Loss: 0.3440 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 104.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 102.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.318042813455655, 68.42105263157895]\n",
      "train Loss: 0.3440 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 120.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 53.96825396825397]\n",
      "test Loss: 0.4061 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 101.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.34080717488789, 47.400611620795104, 64.91228070175438]\n",
      "train Loss: 0.3442 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4054 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 88.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.16143497757848, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 48.01223241590214, 66.66666666666667]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 92.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 85.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4049 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 98.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.89237668161435, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 100.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 89.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 79.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.89237668161435, 48.92966360856269, 66.08187134502924]\n",
      "train Loss: 0.3439 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 106.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 92.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.80269058295964, 48.92966360856269, 68.42105263157895]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 92.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 107.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4064 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 87.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.25112107623319, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 91.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 102.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.71300448430493, 49.235474006116206, 68.42105263157895]\n",
      "train Loss: 0.3438 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4063 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.4304932735426, 46.788990825688074, 66.66666666666667]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 110.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.54128440366973, 68.42105263157895]\n",
      "train Loss: 0.3436 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 99.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 94.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 115.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4060 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 47.09480122324159, 67.25146198830409]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4190 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4061 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 92.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 87.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 94.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 102.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.09480122324159, 68.42105263157895]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.318042813455655, 66.08187134502924]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6066\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 119.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 125.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 108.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 66.66666666666667]\n",
      "train Loss: 0.3436 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 123.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 124.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4060 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.400611620795104, 68.42105263157895]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3435 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 55.55555555555556]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 101.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 53.96825396825397]\n",
      "test Loss: 0.4059 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 102.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.84709480122324, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4190 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4063 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 98.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 47.400611620795104, 66.08187134502924]\n",
      "train Loss: 0.3435 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4059 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 96.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 94.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 107.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.16143497757848, 48.318042813455655, 67.25146198830409]\n",
      "train Loss: 0.3433 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.62385321100918, 68.42105263157895]\n",
      "train Loss: 0.3433 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 92.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.98206278026906, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 91.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 96.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 66.66666666666667]\n",
      "train Loss: 0.3432 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 140.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.62331838565022, 49.54128440366973, 67.83625730994152]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 104.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 82.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.25112107623319, 45.87155963302752, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 113.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 111.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4054 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 48.92966360856269, 69.00584795321637]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 103.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.62385321100918, 65.49707602339181]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 67.83625730994152]\n",
      "train Loss: 0.3430 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 99.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.400611620795104, 66.66666666666667]\n",
      "train Loss: 0.3432 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.25112107623319, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4058 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 96.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.4439461883408, 49.84709480122324, 65.49707602339181]\n",
      "train Loss: 0.3429 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 103.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4066 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 110.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4063 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 95.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4176 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 94.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 97.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 49.235474006116206, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 99.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.62385321100918, 66.66666666666667]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4179 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 98.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 49.235474006116206, 66.08187134502924]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.53363228699551, 50.45871559633027, 67.83625730994152]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3428 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 115.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 47.400611620795104, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 99.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.25112107623319, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3427 Average Accuracy: 86.8468\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 109.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4175 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 108.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 90.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.16143497757848, 47.706422018348626, 68.42105263157895]\n",
      "train Loss: 0.3428 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 86.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4176 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 121.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3427 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 155.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4179 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 157.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 123.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.318042813455655, 68.42105263157895]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 143.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 107.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 114.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.01223241590214, 66.08187134502924]\n",
      "train Loss: 0.3427 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 140.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 143.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4057 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.62331838565022, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 135.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4061 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 93.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3426 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4180 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 115.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4069 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 96.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.89237668161435, 48.92966360856269, 66.08187134502924]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 108.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 105.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 46.788990825688074, 67.25146198830409]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6066\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 114.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 119.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 98.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 116.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 92.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 49.84709480122324, 66.66666666666667]\n",
      "train Loss: 0.3425 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 111.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 114.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 95.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.62385321100918, 66.66666666666667]\n",
      "train Loss: 0.3426 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 114.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4062 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 139/139 [00:01<00:00, 103.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.706422018348626, 68.42105263157895]\n",
      "train Loss: 0.3425 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:00<00:00, 117.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:00<00:00, 118.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Training complete in 3m 25s\n",
      "Best Accuracy: 84.368736\n"
     ]
    }
   ],
   "source": [
    "#@title Train Baseline\n",
    "# specify loss function\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inception = inception_v3_merge(pretrained=False)#, metadata_size=64)\n",
    "\n",
    "state_dict = load_state_dict_from_url(model_urls[\"inception_v3_google\"], progress=True)\n",
    "inception.load_state_dict(state_dict, strict=False)\n",
    "inception.to(device)\n",
    "\n",
    " \n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/resnet18-f37072fd.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/vit_b_16-c867db91.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://github.com/wkcn/TinyViT-model-zoo/releases/download/checkpoints/tiny_vit_21m_1k.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\", progress=True)\n",
    "\n",
    "#model = torchvision.models.vit_b_16(weights = None, num_classes = 5)\n",
    "#model = tiny_vit_21m_224(num_classes = 5)\n",
    "#model = torchvision.models.resnet34(weights = None, num_classes = 5)\n",
    "#model = torchvision.models.inception_v3(weights = None, num_classes = 5)\n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "model = SimpleNet()\n",
    "for name, param in weights.items():\n",
    "  if name not in model.state_dict() or model.state_dict()[name].size() != param.size():\n",
    "    continue\n",
    "    # backwards compatibility for serialized parameters\n",
    "  param = param.data\n",
    "  #model.state_dict()[name].copy_(param)\n",
    "#model.load_state_dict(torch.load( 'F:/Scales/inception_v3_classification_image_only_temp.pth'))\n",
    "#model.load_state_dict(weights, strict= False)\n",
    "#model = mobilenetv2(num_classes=5, width_mult=0.2)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([2949/1561,2949/1034,2949/271,2949/83,2949/20]).to(device))\n",
    "#criterion = CBFocalLoss(gamma = 0.5)\n",
    "#criterion = FocalLoss2(gamma = 2)\n",
    "#criterion = CBCrossEntropy()\n",
    "#inception.load_state_dict(torch.load( 'F:/Scales/Gulf Menhaden/inception_v3_classification_source2.pth'))\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 25, gamma=0.2)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [50, 100], gamma=0.2)\n",
    "model_name = \"inception\"\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[inception, loss_list, acc_list, res, training_res] = train_model_classification(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs=100,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "\n",
    "torch.save(inception.state_dict(), 'F:/Scales/Classification_Atlantic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYxZls57x3si",
    "outputId": "76160dd5-19cc-4702-9ba9-a26b47526417"
   },
   "outputs": [],
   "source": [
    "#model = inception_v3_merge(pretrained=False)\n",
    "model = SimpleNet()\n",
    "model.load_state_dict(torch.load( 'F:/Scales/Classification_Atlantic.pth'))\n",
    "infile = open(val_csv_path,'r')\n",
    "outfile = open(val_csv_path[:-4] + \"_results_meta_only.csv\",'w')\n",
    "lines = infile.readlines()\n",
    "infile.close()\n",
    "outfile.write(lines[0].strip()+\", model age\\n\")\n",
    "model.to(device)\n",
    "for i in range(1,len(lines)):\n",
    "  if(len(lines[i])>0):\n",
    "    (image, wt), age = val_loader.dataset.__getitem__(i-1)\n",
    "    image = image.to(device).unsqueeze(0)\n",
    "\n",
    "    wt = wt.to(device).float().unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      outputs = model( wt)\n",
    "      outputs = torch.squeeze(outputs)\n",
    "      _, preds = torch.max(outputs, 0)\n",
    "      #print(i,preds)\n",
    "      outfile.write(lines[i].strip()+\",%d\\n\"%(preds))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7N8TAGmNs1O",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "a1d0e675-740d-462c-ea33-e11673175998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5767 Average Accuracy: 88.9115\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2611 Average Accuracy: 94.7236\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4402 Average Accuracy: 89.8623\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4942 Average Accuracy: 90.8104\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2970 Average Accuracy: 91.4573\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4460 Average Accuracy: 86.9837\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5005 Average Accuracy: 90.8783\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2949 Average Accuracy: 91.2060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5216 Average Accuracy: 87.1089\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:43<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6128 Average Accuracy: 87.7247\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3419 Average Accuracy: 86.9347\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4285 Average Accuracy: 86.3579\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5175 Average Accuracy: 89.9288\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3197 Average Accuracy: 91.2060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4341 Average Accuracy: 88.8611\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4246 Average Accuracy: 92.5059\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2648 Average Accuracy: 92.4623\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3793 Average Accuracy: 88.4856\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3528 Average Accuracy: 93.5232\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2165 Average Accuracy: 93.9698\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3961 Average Accuracy: 88.6108\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2964 Average Accuracy: 94.9814\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1888 Average Accuracy: 96.4824\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4327 Average Accuracy: 90.3630\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2608 Average Accuracy: 95.2187\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1971 Average Accuracy: 95.4774\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4154 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2316 Average Accuracy: 95.8630\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1935 Average Accuracy: 95.4774\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4810 Average Accuracy: 88.4856\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2148 Average Accuracy: 96.6429\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1734 Average Accuracy: 94.9749\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4748 Average Accuracy: 88.9862\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1632 Average Accuracy: 97.1177\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1961 Average Accuracy: 96.2312\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5096 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1708 Average Accuracy: 96.9820\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1782 Average Accuracy: 96.2312\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5358 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1278 Average Accuracy: 97.2872\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1883 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5499 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1514 Average Accuracy: 97.3889\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1794 Average Accuracy: 96.4824\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5679 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1297 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1896 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5488 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1297 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1928 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5669 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1275 Average Accuracy: 97.1516\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1587 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5641 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1060 Average Accuracy: 98.2367\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1645 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5400 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1248 Average Accuracy: 97.5246\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1764 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5723 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1299 Average Accuracy: 97.5924\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1852 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5510 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1210 Average Accuracy: 97.5924\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1850 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5819 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1351 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1747 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5669 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1307 Average Accuracy: 97.9315\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1461 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5657 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1239 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1625 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5462 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0976 Average Accuracy: 97.8976\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1820 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5457 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1270 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1895 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5932 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1153 Average Accuracy: 97.9315\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1826 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5597 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1111 Average Accuracy: 97.6941\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1300 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5802 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1294 Average Accuracy: 97.4907\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1611 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5519 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1224 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1953 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6108 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1186 Average Accuracy: 97.6263\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1793 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5937 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1097 Average Accuracy: 97.5585\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1845 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5667 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1174 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1607 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5572 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1323 Average Accuracy: 97.3550\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1736 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5909 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1282 Average Accuracy: 97.4229\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1799 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5747 Average Accuracy: 89.8623\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1116 Average Accuracy: 97.9654\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1802 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5782 Average Accuracy: 89.2365\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1248 Average Accuracy: 97.6941\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1882 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5608 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1392 Average Accuracy: 97.4907\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1869 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5839 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1209 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 132/132 [00:04<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1689 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 266/266 [00:08<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5689 Average Accuracy: 89.6120\n",
      "\n",
      "Training complete in 37m 6s\n",
      "Best Accuracy: 97.236183\n"
     ]
    }
   ],
   "source": [
    "#@title Train Stage 2\n",
    "# specify loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([2949/1561,2949/1034,2949/271,2949/83,2949/20]).to(device))\n",
    "#criterion = CBFocalLoss(gamma = 0.5)\n",
    "criterion = CBCrossEntropy()\n",
    "\n",
    "# load model\n",
    "inception.load_state_dict(torch.load( 'F:/Scales/inception_v3_classification_ce_baseline.pth'))\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 15, gamma=0.2)\n",
    "\n",
    "model_name = \"inception\"\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[inception, loss_list, acc_list, res, training_res] = train_model_classification(\n",
    "    inception,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs=40,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "\n",
    "torch.save(inception.state_dict(), 'F:/Scales/inception_v3_classification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdb2ba1e"
   },
   "outputs": [],
   "source": [
    "inception.load_state_dict(torch.load( 'F:/Scales/Gulf Menhaden/inception_v3_classification_source2.pth'))\n",
    "inception = inception.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DlkmMwdbT8kh"
   },
   "outputs": [],
   "source": [
    "#@title Test Model\n",
    "def test_model_classification(\n",
    "    model, dataloaders, criterion, device, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_res = []\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    phase = \"test\"\n",
    "    if phase == \"train\":\n",
    "        model.train()  # Set model to training mode\n",
    "    else:\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count_3 = 0\n",
    "\n",
    "    print(\"Phase %s\"%(phase))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Iterate over data.\n",
    "    print(\"expecting data\")\n",
    "    cm = np.zeros((5,5))\n",
    "    for (inputs, wt_l), labels in tqdm(dataloaders):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        wt_l = wt_l.to(device).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "            if is_inception and phase == \"train\":\n",
    "                # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                outputs, aux_outputs = model(inputs)#, wt_l)\n",
    "\n",
    "                loss1 = criterion(outputs, labels)\n",
    "                loss2 = criterion(aux_outputs, labels)\n",
    "                loss = loss1 + 0.4 * loss2\n",
    "            else:\n",
    "                outputs = model(wt_l)#, wt_l)\n",
    "                outputs = torch.squeeze(outputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            cm[preds[i], labels.data[i]] +=1\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = 100.0 * running_corrects / len(dataloaders.dataset)\n",
    "        running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "        \n",
    "        print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "        print(running_res)\n",
    "        # deep copy the model\n",
    "        if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "            best_train_acc = epoch_acc\n",
    "            training_res = running_res.copy()\n",
    "\n",
    "        if (phase == \"val\" or phase == \"test\") and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            res = running_res.copy()\n",
    "\n",
    "        if phase == \"val\" or phase == \"test\":\n",
    "            loss_list.append(epoch_loss)\n",
    "            acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [acc_list, res], cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hsjzHYm7t7_k",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Get Feature and Test Model\n",
    "def test_model_classification_feature(\n",
    "    model, dataloader, criterion, device, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_res = []\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    phase = \"test\"\n",
    "    if phase == \"train\":\n",
    "        model.train()  # Set model to training mode\n",
    "    else:\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count_3 = 0\n",
    "\n",
    "    print(\"Phase %s\"%(phase))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Iterate over data.\n",
    "    print(\"expecting data\")\n",
    "    cm = np.zeros((5,5))\n",
    "    train_fea = []\n",
    "    train_label = []\n",
    "    for (inputs, wt_l), labels in tqdm(dataloader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        wt_l = wt_l.to(device).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "            outputs, feature = model.get_fea(inputs, wt_l)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "\n",
    "            features = feature.detach().cpu().numpy()\n",
    "            gt = labels.detach().cpu().numpy()\n",
    "            for i in range(features.shape[0]):\n",
    "                train_fea.append(features[i,:])\n",
    "                train_label.append(gt[i])\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            cm[preds[i], labels.data[i]] +=1\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = 100.0 * running_corrects / len(dataloaders[phase].dataset)\n",
    "        running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "\n",
    "        print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "            best_train_acc = epoch_acc\n",
    "            training_res = running_res.copy()\n",
    "\n",
    "        if (phase == \"val\" or phase == \"test\") and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            res = running_res.copy()\n",
    "\n",
    "        if phase == \"val\" or phase == \"test\":\n",
    "            loss_list.append(epoch_loss)\n",
    "            acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [acc_list, res], cm, train_fea, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "rt_M90E9zOlR",
    "outputId": "5573c4a7-a62b-40f8-e8b7-e4785baaa31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase test\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                        | 1/41 [00:01<00:51,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0112 Average Accuracy: 2.1717\n",
      "[100.0, 83.33333333333333, 88.88888888888889, 0.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                                                     | 2/41 [00:02<00:41,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0196 Average Accuracy: 4.2399\n",
      "[100.0, 86.36363636363636, 88.88888888888889, 75.0, 66.66666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                                                   | 3/41 [00:03<00:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0243 Average Accuracy: 6.4116\n",
      "[100.0, 90.3225806451613, 89.28571428571429, 71.42857142857143, 50.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                                                | 4/41 [00:03<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0292 Average Accuracy: 8.6867\n",
      "[100.0, 92.3076923076923, 92.3076923076923, 66.66666666666667, 40.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                                                              | 5/41 [00:04<00:33,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0321 Average Accuracy: 11.0652\n",
      "[100.0, 94.23076923076923, 93.47826086956522, 72.72727272727273, 42.857142857142854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                                           | 6/41 [00:05<00:33,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0480 Average Accuracy: 12.9266\n",
      "[100.0, 95.3125, 90.19607843137256, 61.111111111111114, 42.857142857142854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                                        | 7/41 [00:06<00:31,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0610 Average Accuracy: 14.8914\n",
      "[100.0, 93.05555555555556, 91.2280701754386, 62.5, 54.54545454545455]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                                      | 8/41 [00:07<00:30,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0714 Average Accuracy: 16.8563\n",
      "[100.0, 93.82716049382717, 90.625, 58.62068965517241, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                                                   | 9/41 [00:08<00:30,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0754 Average Accuracy: 19.2347\n",
      "[100.0, 94.56521739130434, 92.0, 56.666666666666664, 60.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|                                                                                | 10/41 [00:09<00:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0863 Average Accuracy: 21.4064\n",
      "[100.0, 95.14563106796116, 91.56626506024097, 57.57575757575758, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                                             | 11/41 [00:10<00:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0929 Average Accuracy: 23.7849\n",
      "[100.0, 95.76271186440678, 91.11111111111111, 60.0, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                                           | 12/41 [00:11<00:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1012 Average Accuracy: 26.0600\n",
      "[100.0, 95.45454545454545, 90.9090909090909, 61.111111111111114, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|                                                                        | 13/41 [00:12<00:26,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1138 Average Accuracy: 27.9214\n",
      "[100.0, 95.1048951048951, 91.50943396226415, 57.5, 50.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|                                                                     | 14/41 [00:13<00:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1170 Average Accuracy: 30.1965\n",
      "[100.0, 94.96855345911949, 91.66666666666667, 57.142857142857146, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                                   | 15/41 [00:14<00:23,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1242 Average Accuracy: 32.2647\n",
      "[100.0, 94.28571428571429, 91.96428571428571, 55.55555555555556, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                                | 16/41 [00:15<00:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1435 Average Accuracy: 34.0228\n",
      "[100.0, 93.44262295081967, 90.9090909090909, 54.166666666666664, 58.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                              | 17/41 [00:16<00:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1503 Average Accuracy: 36.1944\n",
      "[100.0, 93.33333333333333, 91.33858267716535, 55.76923076923077, 57.69230769230769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                                           | 18/41 [00:17<00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1551 Average Accuracy: 38.3661\n",
      "[100.0, 93.20388349514563, 91.36690647482014, 55.76923076923077, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|                                                         | 19/41 [00:18<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1584 Average Accuracy: 40.7446\n",
      "[100.0, 93.57798165137615, 91.83673469387755, 55.55555555555556, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                                      | 20/41 [00:18<00:19,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1618 Average Accuracy: 42.9162\n",
      "[100.0, 93.96551724137932, 92.15686274509804, 55.357142857142854, 53.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                                   | 21/41 [00:20<00:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1661 Average Accuracy: 45.1913\n",
      "[100.0, 94.26229508196721, 91.92546583850931, 55.932203389830505, 54.83870967741935]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|                                                 | 22/41 [00:20<00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1761 Average Accuracy: 47.3630\n",
      "[90.0, 94.55252918287938, 92.21556886227545, 56.666666666666664, 52.94117647058823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                              | 23/41 [00:21<00:16,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1787 Average Accuracy: 49.8449\n",
      "[91.66666666666667, 94.81481481481481, 92.39766081871345, 58.73015873015873, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                            | 24/41 [00:23<00:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1886 Average Accuracy: 52.0165\n",
      "[92.85714285714286, 94.6236559139785, 92.26519337016575, 59.09090909090909, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                                         | 25/41 [00:23<00:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1962 Average Accuracy: 54.0848\n",
      "[93.75, 93.81443298969072, 92.55319148936171, 58.208955223880594, 57.89473684210526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                                      | 26/41 [00:24<00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2101 Average Accuracy: 56.2565\n",
      "[94.44444444444444, 94.05940594059406, 91.87817258883248, 57.35294117647059, 57.89473684210526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|                                    | 27/41 [00:25<00:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2140 Average Accuracy: 58.5315\n",
      "[94.73684210526316, 94.28571428571429, 92.07920792079207, 59.15492957746479, 56.09756097560975]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|                                 | 28/41 [00:26<00:12,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2191 Average Accuracy: 60.8066\n",
      "[94.73684210526316, 94.46153846153847, 92.01877934272301, 58.333333333333336, 58.13953488372093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                               | 29/41 [00:27<00:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2223 Average Accuracy: 63.1851\n",
      "[95.0, 94.73684210526316, 91.74311926605505, 58.9041095890411, 58.13953488372093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                            | 30/41 [00:28<00:10,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2326 Average Accuracy: 65.2534\n",
      "[95.0, 94.90084985835693, 91.62995594713657, 58.666666666666664, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|                         | 31/41 [00:29<00:09,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2362 Average Accuracy: 67.5284\n",
      "[95.0, 94.78021978021978, 91.91489361702128, 58.97435897435897, 57.4468085106383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                       | 32/41 [00:30<00:08,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2432 Average Accuracy: 69.8035\n",
      "[95.0, 94.96021220159152, 91.66666666666667, 59.25925925925926, 60.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                    | 33/41 [00:31<00:08,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2564 Average Accuracy: 71.7684\n",
      "[95.45454545454545, 94.83204134366925, 91.2, 59.25925925925926, 57.69230769230769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|                  | 34/41 [00:32<00:06,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2668 Average Accuracy: 73.8366\n",
      "[95.83333333333333, 94.5, 91.40625, 58.53658536585366, 57.407407407407405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|               | 35/41 [00:33<00:05,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2800 Average Accuracy: 75.9049\n",
      "[96.0, 94.63414634146342, 90.83969465648855, 59.09090909090909, 58.18181818181818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|             | 36/41 [00:34<00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2915 Average Accuracy: 78.0765\n",
      "[92.3076923076923, 94.5754716981132, 90.74074074074075, 59.550561797752806, 58.18181818181818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|          | 37/41 [00:35<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3004 Average Accuracy: 80.2482\n",
      "[92.3076923076923, 94.70046082949308, 90.3225806451613, 60.43956043956044, 58.62068965517241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|       | 38/41 [00:36<00:02,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3069 Average Accuracy: 82.3164\n",
      "[92.5925925925926, 94.40715883668904, 90.55944055944056, 59.78260869565217, 58.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|     | 39/41 [00:37<00:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3320 Average Accuracy: 84.0745\n",
      "[89.65517241379311, 94.10480349344978, 90.03436426116839, 60.0, 58.73015873015873]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|  | 40/41 [00:38<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3377 Average Accuracy: 86.2461\n",
      "[90.0, 94.01709401709402, 89.70099667774086, 61.224489795918366, 58.73015873015873]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 41/41 [00:38<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3414 Average Accuracy: 86.8666\n",
      "[90.0, 94.08033826638477, 89.43894389438944, 61.224489795918366, 58.73015873015873]\n",
      "\n",
      "Training complete in 0m 39s\n",
      "Best Accuracy: 86.866600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([1,1,1,10,10]).to(device))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/swin_t-704ceda3.pth\", progress=True)\n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5).to(device)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/resnet18-f37072fd.pth\", progress=True)\n",
    "model = torchvision.models.resnet18(weights = None, num_classes = 5).to(device)\n",
    "\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/vit_b_16-c867db91.pth\", progress=True)\n",
    "#model = torchvision.models.vit_b_16(weights = None, num_classes = 5)\n",
    "#model.load_state_dict(torch.load( 'F:/Scales/Atlantic_menhaden_swint_temp.pth'))\n",
    "model.load_state_dict(torch.load( 'F:/Scales/Atlantic_menhaden_resnet.pth'))\n",
    "model_name = \"inception\"\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.001)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[acc_list, res], cm = test_model_classification(\n",
    "    model,\n",
    "    dataloaders[\"test\"],\n",
    "    criterion,\n",
    "    device,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utrK1oShUNop",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "bd3df520-2c16-49d8-f3aa-d6a54bee21cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase test\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                   | 1/42 [00:00<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0381 Average Accuracy: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|                                                                                                                                               | 2/42 [00:01<00:25,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0813 Average Accuracy: 1.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|                                                                                                                                            | 3/42 [00:01<00:23,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1215 Average Accuracy: 2.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|                                                                                                                                        | 4/42 [00:02<00:22,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1666 Average Accuracy: 2.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|                                                                                                                                     | 5/42 [00:03<00:21,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2190 Average Accuracy: 2.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|                                                                                                                                 | 6/42 [00:03<00:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2672 Average Accuracy: 3.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|                                                                                                                             | 7/42 [00:04<00:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3143 Average Accuracy: 4.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|                                                                                                                          | 8/42 [00:04<00:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3614 Average Accuracy: 4.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|                                                                                                                      | 9/42 [00:05<00:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4207 Average Accuracy: 4.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|                                                                                                                  | 10/42 [00:05<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4703 Average Accuracy: 5.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|                                                                                                              | 11/42 [00:06<00:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5144 Average Accuracy: 6.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|                                                                                                           | 12/42 [00:06<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5639 Average Accuracy: 6.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|                                                                                                       | 13/42 [00:07<00:16,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6056 Average Accuracy: 7.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                                                                    | 14/42 [00:08<00:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6587 Average Accuracy: 7.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|                                                                                                | 15/42 [00:08<00:15,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7084 Average Accuracy: 8.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|                                                                                            | 16/42 [00:09<00:14,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7483 Average Accuracy: 8.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                                                                         | 17/42 [00:09<00:14,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7984 Average Accuracy: 9.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|                                                                                     | 18/42 [00:10<00:13,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8381 Average Accuracy: 9.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|                                                                                  | 19/42 [00:10<00:12,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8876 Average Accuracy: 10.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|                                                                              | 20/42 [00:11<00:12,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9320 Average Accuracy: 10.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|                                                                           | 21/42 [00:11<00:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9792 Average Accuracy: 11.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|                                                                       | 22/42 [00:12<00:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0159 Average Accuracy: 12.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|                                                                   | 23/42 [00:13<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0727 Average Accuracy: 12.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|                                                                | 24/42 [00:13<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.1183 Average Accuracy: 13.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                                                            | 25/42 [00:14<00:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.1645 Average Accuracy: 13.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|                                                         | 26/42 [00:14<00:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.2067 Average Accuracy: 14.3273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|                                                     | 27/42 [00:15<00:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.2709 Average Accuracy: 14.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                                                  | 28/42 [00:15<00:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.3176 Average Accuracy: 14.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|                                              | 29/42 [00:16<00:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.3625 Average Accuracy: 15.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|                                          | 30/42 [00:17<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4043 Average Accuracy: 16.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|                                       | 31/42 [00:17<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4418 Average Accuracy: 16.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|                                   | 32/42 [00:18<00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4883 Average Accuracy: 17.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|                                | 33/42 [00:18<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.5340 Average Accuracy: 17.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|                            | 34/42 [00:19<00:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.5642 Average Accuracy: 18.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|                         | 35/42 [00:19<00:03,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.6151 Average Accuracy: 19.4909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|                     | 36/42 [00:20<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.6593 Average Accuracy: 20.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|                 | 37/42 [00:21<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7042 Average Accuracy: 20.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|              | 38/42 [00:21<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7495 Average Accuracy: 20.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|          | 39/42 [00:22<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7951 Average Accuracy: 21.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|       | 40/42 [00:22<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.8371 Average Accuracy: 21.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|   | 41/42 [00:23<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.8821 Average Accuracy: 22.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 42/42 [00:24<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.9250 Average Accuracy: 22.6182\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best Accuracy: 22.618181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([1,1,1,10,10]).to(device))\n",
    "\n",
    "model_name = \"inception\"\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.001)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[acc_list, res], cm, fea, label = test_model_classification_feature(\n",
    "    inception,\n",
    "    dataloaders[\"test\"],\n",
    "    criterion,\n",
    "    device,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "with open(\"val_feas.npy\",'wb') as f:\n",
    "    np.save(f, np.array(fea))\n",
    "with open(\"val_labels.npy\",'wb') as f:\n",
    "    np.save(f, np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8f704836",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "15d8ed39-8e67-43b7-baa0-f19cd24a8012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Age Training Set Prediction Result\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Group (years old)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\pyplot.py:2387\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2383\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2385\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, bottom\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2386\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2342\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2340\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2342\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:538\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    536\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 538\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:420\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(res))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar([0, 1, 2, 3, 4], training_res, width=0.5)\n",
    "\n",
    "plt.title('Classification Age Training Set Prediction Result', fontsize=15)\n",
    "plt.xlabel('Age Group (years old)', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy (%)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "6znhvLKsc7BI",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "2a47543a-75f0-402b-9ba4-978ae905bf6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 98.0295566502463, 84.0, 71.7948717948718, 65.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar([0, 1, 2, 3, 4], res[:5], width=0.5)\n",
    "print(res)\n",
    "plt.title('Classification Age Testing Set Prediction Result', fontsize=15)\n",
    "plt.xlabel('Age Group (years old)', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy (%)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWX3Gh-xZJsK",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "ae737ab4-67c0-4df7-8ca2-9ccc141dbcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23.   1.   0.   0.   0.]\n",
      " [  0. 398.  13.   0.   0.]\n",
      " [  0.   7. 210.   7.   0.]\n",
      " [  0.   0.  23.  56.   7.]\n",
      " [  0.   0.   4.  15.  13.]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
